{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# How to slice and dice the data\n",
    "Below are a series of examples on how to slice and dice the data that is stored in the *.sqlite* file generated by the [MorningStar.com](https://www.morningstar.com) web scraper.\n",
    "\n",
    "##### NOTE:\n",
    "- The data used in the code below come from the *.sqlite* file that is automatically generated by the web scraper once it has been installed and ran locally on your machine. See [README]() for instructions on how to run install and run the scraper.\n",
    "- Navigation links only when using [Jupyter notebook](https://jupyter.org/).\n",
    "\n",
    "\n",
    "**Content**\n",
    "\n",
    "1. [Required modules and matplotlib backend](#modules)\n",
    "1. [Creating a master (bridge table) DataFrame instance using the DataFrames class](#master)\n",
    "1. [Methods for creating DataFrame instances](#methods)\n",
    "    1. `quoteheader` - [MorningStar (MS) Quote Header](#quote)\n",
    "    1. `valuation` - [MS Valuation table with Price Ratios (P/E, P/S, P/B, P/C) for the past 10 yrs](#val)\n",
    "    1. `keyratios` - [MS Ratio - Key Financial Ratios & Values](#keyratios)\n",
    "    1. `finhealth` - [MS Ratio - Financial Health](#finhealth)\n",
    "    1. `profitability` - [MS Ratio - Profitability](#prof)\n",
    "    1. `growth` - [MS Ratio - Growth](#growth)\n",
    "    1. `cfhealth` - [MS Ratio - Cash Flow Health](#cfh)\n",
    "    1. `efficiency` - [MS Ratio - Efficiency](#eff)\n",
    "    1. `annualIS` - [MS Annual Income Statements](#isa)\n",
    "    1. `quarterlyIS` - [MS Quarterly Income Statements](#isq)\n",
    "    1. `annualBS` - [MS Annual Balance Sheets](#bsa)\n",
    "    1. `quarterlyBS` - [MS Quarterly Balance Sheets](#bsq)\n",
    "    1. `annualCF` - [MS Annual Cash Flow Statements](#cfa)\n",
    "    1. `quarterlyCF` - [MS Quarterly Cash Flow Statements](#cfq)\n",
    "    1. `insider_trades` - [Insider Transactions](#it)\n",
    "1. [Performing statistical analysis](#stats)\n",
    "    1. [Count of database records](#stats)\n",
    "    1. [Last updated dates](#lastupdate)\n",
    "    1. [Number of records by security type](#type)\n",
    "    1. [Number of records by country, based on the location of exchanges](#country)\n",
    "    1. [Number of records per exchange](#exchange)\n",
    "    1. [Number of stocks by sector](#sector)\n",
    "    1. [Number of stocks by industry](#industry)\n",
    "    1. [Mean price ratios (P/E, P/S, P/B, P/CF) of stocks by sectors](#meanpr)\n",
    "1. [Applying various criteria to filter common stocks](#value) *(in progress)*\n",
    "1. [Additional sample / test code](#additional) *(in progress)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modules\"></a>\n",
    "# Required modules and matplotlib backend"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install IPython\n",
    "#!pip3 install sqlite3\n",
    "#!pip3 install json\n",
    "# !pip3 install sys\n",
    "# !pip3 install re\n",
    "# !pip3 install os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:25.666578Z",
     "start_time": "2025-05-20T05:20:22.725726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from pandas) (2.2.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (2.2.4)\r\n",
      "Requirement already satisfied: IPython in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (8.30.0)\r\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from IPython) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from IPython) (0.19.2)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from IPython) (0.1.6)\r\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from IPython) (3.0.43)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from IPython) (2.15.1)\r\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from IPython) (0.2.0)\r\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from IPython) (5.14.3)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from IPython) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from jedi>=0.16->IPython) (0.8.4)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from pexpect>4.3->IPython) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython) (0.2.5)\r\n",
      "Requirement already satisfied: executing in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from stack-data->IPython) (0.8.3)\r\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from stack-data->IPython) (3.0.0)\r\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from stack-data->IPython) (0.2.2)\r\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip3 install matplotlib.pyplot\n",
    "!pip3 install matplotlib\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "#!pip3 install dataframes #module containing class used to create DataFrame objects from SQLite database file\n",
    "#!pip3 install datetime\n",
    "#!pip3 install re\n",
    "!pip3 install requests"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.484485Z",
     "start_time": "2025-05-20T05:20:25.734143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (3.10.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from matplotlib) (4.57.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from matplotlib) (2.2.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from matplotlib) (24.2)\r\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from matplotlib) (11.2.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from matplotlib) (3.2.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from pandas) (2.2.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (2.2.4)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from requests) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from requests) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from requests) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/mstables/lib/python3.12/site-packages (from requests) (2025.4.26)\r\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "class DataFrames():\n",
    "\n",
    "    db_file = 'datab/mstables.sqlite' # Standard db file name\n",
    "\n",
    "    def __init__(self, file = db_file):\n",
    "\n",
    "        msg = 'Creating initial DataFrames objects from file {}...\\n'\n",
    "        print(msg.format(file))\n",
    "\n",
    "        self.conn = sqlite3.connect(\n",
    "            file, detect_types=sqlite3.PARSE_COLNAMES)\n",
    "        self.cur = self.conn.cursor()\n",
    "\n",
    "        # Row Headers\n",
    "        colheaders = self.table('ColHeaders', True)\n",
    "        self.colheaders = colheaders.set_index('id')\n",
    "\n",
    "        # Dates and time references\n",
    "        timerefs = self.table('TimeRefs', True)\n",
    "        self.timerefs = timerefs.set_index('id').replace(['', '—'], None)\n",
    "\n",
    "        # Reference tables\n",
    "        self.urls = self.table('URLs', True)\n",
    "        self.securitytypes = self.table('SecurityTypes', True)\n",
    "        self.tickers = self.table('Tickers', True)\n",
    "        self.sectors = self.table('Sectors', True)\n",
    "        self.industries = self.table('Industries', True)\n",
    "        self.styles = self.table('StockStyles', True)\n",
    "        self.exchanges = self.table('Exchanges', True)\n",
    "        self.countries = (self.table('Countries', True)\n",
    "            .rename(columns={'a2_iso':'country_c2', 'a3_un':'country_c3'}))\n",
    "        self.companies = self.table('Companies', True)\n",
    "        self.currencies = self.table('Currencies', True)\n",
    "        self.stocktypes = self.table('StockTypes', True)\n",
    "\n",
    "        #self.fetchedurls = self.table('Fetched_urls', True)\n",
    "\n",
    "        # Master table\n",
    "        self.master0 = self.table('Master', True)\n",
    "\n",
    "        # Merge Tables\n",
    "        self.master = (self.master0\n",
    "        # Ticker Symbols\n",
    "         .merge(self.tickers, left_on='ticker_id', right_on='id')\n",
    "         .drop(['id'], axis=1)\n",
    "        # Company / Security Name\n",
    "         .merge(self.companies, left_on='company_id', right_on='id')\n",
    "         .drop(['id', 'company_id'], axis=1)\n",
    "        # Exchanges\n",
    "         .merge(self.exchanges, left_on='exchange_id', right_on='id')\n",
    "         .drop(['id'], axis=1)\n",
    "        # Industries\n",
    "         .merge(self.industries, left_on='industry_id', right_on='id')\n",
    "         .drop(['id', 'industry_id'], axis=1)\n",
    "        # Sectors\n",
    "         .merge(self.sectors, left_on='sector_id', right_on='id')\n",
    "         .drop(['id', 'sector_id'], axis=1)\n",
    "        # Countries\n",
    "         .merge(self.countries, left_on='country_id', right_on='id')\n",
    "         .drop(['id', 'country_id'], axis=1)\n",
    "        # Security Types\n",
    "         .merge(self.securitytypes, left_on='security_type_id', right_on='id')\n",
    "         .drop(['id', 'security_type_id'], axis=1)\n",
    "        # Stock Types\n",
    "         .merge(self.stocktypes, left_on='stock_type_id', right_on='id')\n",
    "         .drop(['id', 'stock_type_id'], axis=1)\n",
    "        # Stock Style Types\n",
    "         .merge(self.styles, left_on='style_id', right_on='id')\n",
    "         .drop(['id', 'style_id'], axis=1)\n",
    "        # Quote Header Info\n",
    "         .merge(self.quoteheader(), on=['ticker_id', 'exchange_id'])\n",
    "         .rename(columns={'fpe':'PE_Forward'})\n",
    "        # Currency\n",
    "         .merge(self.currencies, left_on='currency_id', right_on='id')\n",
    "         .drop(['id', 'currency_id'], axis=1)\n",
    "        # Fiscal Year End\n",
    "         .merge(self.timerefs, left_on='fyend_id', right_on='id')\n",
    "         .drop(['fyend_id'], axis=1)\n",
    "         .rename(columns={'dates':'fy_end'})\n",
    "        )\n",
    "        # Change date columns to TimeFrames\n",
    "        self.master['fy_end'] = pd.to_datetime(self.master['fy_end'])\n",
    "        self.master['update_date'] = pd.to_datetime(self.master['update_date'])\n",
    "        self.master['lastdate'] = pd.to_datetime(self.master['lastdate'])\n",
    "        self.master['_52wk_hi'] = self.master['_52wk_hi'].astype('float')\n",
    "        self.master['_52wk_lo'] = self.master['_52wk_lo'].astype('float')\n",
    "        self.master['lastprice'] = self.master['lastprice'].astype('float')\n",
    "        self.master['openprice'] = self.master['openprice'].astype('float')\n",
    "\n",
    "        print('\\nInitial DataFrames created successfully.')\n",
    "\n",
    "\n",
    "    def quoteheader(self):\n",
    "        return self.table('MSheader')\n",
    "\n",
    "\n",
    "    def valuation(self):\n",
    "        # Create DataFrame\n",
    "        val = self.table('MSvaluation')\n",
    "\n",
    "        # Rename column headers with actual year values\n",
    "        yrs = val.iloc[0, 2:13].replace(self.timerefs['dates']).to_dict()\n",
    "        cols = val.columns[:13].values.tolist() + list(map(\n",
    "            lambda col: ''.join([col[:3], yrs[col[3:]]]), val.columns[13:]))\n",
    "        val.columns = cols\n",
    "\n",
    "        # Resize and reorder columns\n",
    "        val = val.set_index(['exchange_id', 'ticker_id']).iloc[:, 11:]\n",
    "\n",
    "        return val\n",
    "\n",
    "\n",
    "    def keyratios(self):\n",
    "        keyr = self.table('MSfinancials')\n",
    "        yr_cols = ['Y0', 'Y1', 'Y2', 'Y3', 'Y4', 'Y5', 'Y6',\n",
    "            'Y7', 'Y8', 'Y9', 'Y10']\n",
    "        keyr = self.get_yrcolumns(keyr, yr_cols)\n",
    "        keyr[yr_cols[:-1]] = keyr[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return keyr\n",
    "\n",
    "\n",
    "    def finhealth(self):\n",
    "        finan = self.table('MSratio_financial')\n",
    "        yr_cols = [col for col in finan.columns if col.startswith('fh_Y')]\n",
    "        finan = self.get_yrcolumns(finan, yr_cols)\n",
    "        finan[yr_cols[:-1]] = finan[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return finan\n",
    "\n",
    "\n",
    "    def profitability(self):\n",
    "        profit= self.table('MSratio_profitability')\n",
    "        yr_cols = [col for col in profit.columns if col.startswith('pr_Y')]\n",
    "        profit = self.get_yrcolumns(profit, yr_cols)\n",
    "        profit[yr_cols[:-1]] = profit[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return profit\n",
    "\n",
    "\n",
    "    def growth(self):\n",
    "        growth = self.table('MSratio_growth')\n",
    "        yr_cols = [col for col in growth.columns if col.startswith('gr_Y')]\n",
    "        growth = self.get_yrcolumns(growth, yr_cols)\n",
    "        growth[yr_cols[:-1]] = growth[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return growth\n",
    "\n",
    "\n",
    "    def cfhealth(self):\n",
    "        cfhealth = self.table('MSratio_cashflow')\n",
    "        yr_cols = [col for col in cfhealth.columns if col.startswith('cf_Y')]\n",
    "        cfhealth = self.get_yrcolumns(cfhealth, yr_cols)\n",
    "        cfhealth[yr_cols[:-1]] = cfhealth[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return cfhealth\n",
    "\n",
    "\n",
    "    def efficiency(self):\n",
    "        effic = self.table('MSratio_efficiency')\n",
    "        yr_cols = [col for col in effic.columns if col.startswith('ef_Y')]\n",
    "        effic = self.get_yrcolumns(effic, yr_cols)\n",
    "        effic[yr_cols[:-1]] = effic[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return effic\n",
    "\n",
    "    # Income Statement - Annual\n",
    "    def annualIS(self):\n",
    "        rep_is_yr = self.table('MSreport_is_yr')\n",
    "        yr_cols = [col for col in rep_is_yr.columns\n",
    "                    if col.startswith('Year_Y')]\n",
    "        rep_is_yr = self.get_yrcolumns(rep_is_yr, yr_cols)\n",
    "        rep_is_yr[yr_cols[:-1]] = rep_is_yr[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return rep_is_yr\n",
    "\n",
    "    # Income Statement - Quarterly\n",
    "    def quarterlyIS(self):\n",
    "        rep_is_qt = self.table('MSreport_is_qt')\n",
    "        yr_cols = [col for col in rep_is_qt.columns\n",
    "                    if col.startswith('Year_Y')]\n",
    "        rep_is_qt = self.get_yrcolumns(rep_is_qt, yr_cols)\n",
    "        rep_is_qt[yr_cols[:-1]] = rep_is_qt[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return rep_is_qt\n",
    "\n",
    "    # Balance Sheet - Annual\n",
    "    def annualBS(self):\n",
    "        rep_bs_yr = self.table('MSreport_bs_yr')\n",
    "        yr_cols = [col for col in rep_bs_yr.columns\n",
    "                    if col.startswith('Year_Y')]\n",
    "        rep_bs_yr = self.get_yrcolumns(rep_bs_yr, yr_cols)\n",
    "        rep_bs_yr[yr_cols[:-1]] = rep_bs_yr[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return rep_bs_yr\n",
    "\n",
    "    # Balance Sheet - Quarterly\n",
    "    def quarterlyBS(self):\n",
    "        rep_bs_qt = self.table('MSreport_bs_qt')\n",
    "        yr_cols = [col for col in rep_bs_qt.columns\n",
    "                    if col.startswith('Year_Y')]\n",
    "        rep_bs_qt = self.get_yrcolumns(rep_bs_qt, yr_cols)\n",
    "        rep_bs_qt[yr_cols[:-1]] = rep_bs_qt[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return rep_bs_qt\n",
    "\n",
    "    # Cashflow Statement - Annual\n",
    "    def annualCF(self):\n",
    "        rep_cf_yr = self.table('MSreport_cf_yr')\n",
    "        yr_cols = [col for col in rep_cf_yr.columns\n",
    "                    if col.startswith('Year_Y')]\n",
    "        rep_cf_yr = self.get_yrcolumns(rep_cf_yr, yr_cols)\n",
    "        rep_cf_yr[yr_cols[:-1]] = rep_cf_yr[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return rep_cf_yr\n",
    "\n",
    "    # Cashflow Statement - Quarterly\n",
    "    def quarterlyCF(self):\n",
    "        rep_cf_qt = self.table('MSreport_cf_qt')\n",
    "        yr_cols = [col for col in rep_cf_qt.columns\n",
    "                    if col.startswith('Year_Y')]\n",
    "        rep_cf_qt = self.get_yrcolumns(rep_cf_qt, yr_cols)\n",
    "        rep_cf_qt[yr_cols[:-1]] = rep_cf_qt[yr_cols[:-1]].astype('datetime64')\n",
    "\n",
    "        return rep_cf_qt\n",
    "\n",
    "    # 10yr Price History\n",
    "    def priceHistory(self):\n",
    "\n",
    "        return self.table('MSpricehistory')\n",
    "\n",
    "\n",
    "    def insider_trades(self):\n",
    "        df_insiders = self.table('Insiders', False)\n",
    "        df_tradetypes = self.table('TransactionType', False)\n",
    "        df_trades = self.table('InsiderTransactions', False)\n",
    "        df_trades['date'] = pd.to_datetime(df_trades['date'])\n",
    "        df = (df_trades\n",
    "            .merge(df_insiders, left_on='name_id', right_on='id')\n",
    "            .drop(['id', 'name_id'], axis=1)\n",
    "            .merge(df_tradetypes, left_on='transaction_id', right_on='id')\n",
    "            .drop(['id', 'transaction_id'], axis=1)\n",
    "            )\n",
    "        return df\n",
    "\n",
    "\n",
    "    def get_yrcolumns(self, df, cols):\n",
    "        for yr in cols:\n",
    "            df = (df.merge(self.timerefs, left_on=yr, right_on='id')\n",
    "                .drop(yr, axis=1).rename(columns={'dates':yr}))\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def table(self, tbl, prnt = False):\n",
    "        self.cur.execute('SELECT * FROM {}'.format(tbl))\n",
    "        cols = list(zip(*self.cur.description))[0]\n",
    "\n",
    "        try:\n",
    "            if prnt == True:\n",
    "                msg = '\\t- DataFrame \\'df.{}\\' ...'\n",
    "                print(msg.format(tbl.lower()))\n",
    "            return pd.DataFrame(self.cur.fetchall(), columns=cols)\n",
    "        except:\n",
    "            raise\n",
    "\n",
    "\n",
    "    def __del__(self):\n",
    "        self.cur.close()\n",
    "        self.conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.516991Z",
     "start_time": "2025-05-20T05:20:29.495628Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from src import dataframes, fetch\n",
    "import datetime as DT\n",
    "import re\n",
    "import sqlite3\n",
    "# from mstables import parse\n",
    "\n",
    "\n",
    "# Reload in case changes have been made to module file\n",
    "from importlib import reload\n",
    "reload(dataframes);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.624325Z",
     "start_time": "2025-05-20T05:20:29.527666Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input//api.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# %matplotlib notebook\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataframes, fetch\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mDT\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/mstables/src/dataframes.py:8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m fetch\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mDataFrames\u001B[39;00m():\n",
      "File \u001B[0;32m~/PycharmProjects/mstables/src/fetch.py:563\u001B[0m\n\u001B[1;32m    561\u001B[0m today   \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mtoday()\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    562\u001B[0m sql_cmds \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124msql_cmd/\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(fd_input, \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 563\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m/api.json\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(fd_input)) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m    564\u001B[0m \tapis \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(file)\n\u001B[1;32m    565\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m/tables.json\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(fd_input)) \u001B[38;5;28;01mas\u001B[39;00m file:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../input//api.json'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "db_file_name = 'data/mstables.sqlite'\n",
    "\n",
    "while True:\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_file_name)\n",
    "            cur = conn.cursor()\n",
    "        except sqlite3.OperationalError as S:\n",
    "            fetch.print_('')\n",
    "            print('\\tError - sqlite3 error: {}'.format(S))\n",
    "            continue\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\nGoodbye!')\n",
    "            exit()\n",
    "        except:\n",
    "            raise\n",
    "        break\n",
    "\n",
    "# Get list of fetched urls from Fetched_urls\n",
    "\"\"\"\n",
    "cols = 'url_id, ticker_id, exch_id, fetch_date, source_text'\n",
    "sql = '''SELECT {} FROM Fetched_urls\n",
    "        WHERE status_code = 200 AND source_text IS NOT NULL\n",
    "        ORDER BY ticker_id asc, url_id desc'''\n",
    "sql = sql.format(cols)\n",
    "fetched = fetch.db_execute(cur, sql).fetchall()\n",
    "\n",
    "\n",
    "# Call parsing methods\n",
    "parsing(conn, cur, fetched)\n",
    "\n",
    "\"\"\"\n",
    "# Save db and close db connection\n",
    "# fetch.save_db(conn)\n",
    "cur.close()\n",
    "conn.close()\n",
    "fetched = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.645449Z",
     "start_time": "2025-05-20T01:34:10.161607Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sqlite3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m----> 5\u001B[0m     conn \u001B[38;5;241m=\u001B[39m sqlite3\u001B[38;5;241m.\u001B[39mconnect(db_file_name)\n\u001B[1;32m      6\u001B[0m     cur \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mcursor()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'sqlite3' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m     conn \u001B[38;5;241m=\u001B[39m sqlite3\u001B[38;5;241m.\u001B[39mconnect(db_file_name)\n\u001B[1;32m      6\u001B[0m     cur \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mcursor()\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m sqlite3\u001B[38;5;241m.\u001B[39mOperationalError \u001B[38;5;28;01mas\u001B[39;00m S:\n\u001B[1;32m      8\u001B[0m     fetch\u001B[38;5;241m.\u001B[39mprint_(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mError - sqlite3 error: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(S))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'sqlite3' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to the top](#top)\n",
    "<a id=\"master\"></a>\n",
    "# Creating the master DataFrame instance\n",
    "The DataFrames class is part of the [dataframes module](src/dataframes.py)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.659346Z",
     "start_time": "2025-04-13T22:13:30.536447Z"
    }
   },
   "source": [
    "db_file_name = 'mstables' # SQLite database file that contains the data to be analyzed\n",
    "df = dataframes.DataFrames(f'db/{db_file_name}.sqlite')\n",
    "df"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial DataFrames objects from file db/mstables.sqlite...\n",
      "\n",
      "\t- DataFrame 'df.colheaders' ...\n",
      "\t- DataFrame 'df.timerefs' ...\n",
      "\t- DataFrame 'df.urls' ...\n",
      "\t- DataFrame 'df.securitytypes' ...\n",
      "\t- DataFrame 'df.tickers' ...\n",
      "\t- DataFrame 'df.sectors' ...\n",
      "\t- DataFrame 'df.industries' ...\n",
      "\t- DataFrame 'df.stockstyles' ...\n",
      "\t- DataFrame 'df.exchanges' ...\n",
      "\t- DataFrame 'df.countries' ...\n",
      "\t- DataFrame 'df.companies' ...\n",
      "\t- DataFrame 'df.currencies' ...\n",
      "\t- DataFrame 'df.stocktypes' ...\n",
      "\t- DataFrame 'df.master' ...\n",
      "\n",
      "Initial DataFrames created successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dataframes.DataFrames at 0x108b45b50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "print(df.timerefs, '\\nhere are timerefs\\n',\n",
    "df.urls,'\\nhere are urls\\n',\n",
    "df.securitytypes,'\\nhere are securitytypes\\n',\n",
    "df.tickers,'\\nhere are tickers\\n',\n",
    "df.sectors,'\\nhere are sectors\\n',\n",
    "df.industries,'\\nhere are industries\\n',\n",
    "df.exchanges,'\\nhere are exchanges\\n',\n",
    "df.countries,'\\nhere are countries\\n',\n",
    "df.companies,'\\nhere are companies\\n',\n",
    "df.currencies,'\\nhere are currencies\\n',\n",
    "df.stocktypes,'\\nhere are stocktype\\n')\n",
    "\n",
    "\n",
    "display(df)\n",
    "#df.stockstyles has an issue?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.661806Z",
     "start_time": "2025-04-13T22:13:31.388628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             dates\n",
      "id                \n",
      "1             None\n",
      "2       2012-06-30\n",
      "3       2021-12-31\n",
      "9       2004-09-30\n",
      "10      2012-12-31\n",
      "...            ...\n",
      "87635   2018-12-30\n",
      "89191   2017-07-31\n",
      "96482   2022-04-19\n",
      "98856   2009-09-30\n",
      "102475  2012-02-28\n",
      "\n",
      "[343 rows x 1 columns] \n",
      "here are timerefs\n",
      "     id                                                url\n",
      "0    1  https://www.morningstar.com/api/v2/search/Secu...\n",
      "1    2  https://www.morningstar.com/api/v2/search/Secu...\n",
      "2    3  https://www.morningstar.com/api/v2/search/secu...\n",
      "3    4  http://quotes.morningstar.com/stockq/c-company...\n",
      "4    5  http://quotes.morningstar.com/stockq/c-header?...\n",
      "5    6  http://financials.morningstar.com/valuate/valu...\n",
      "6    7  http://financials.morningstar.com/finan/financ...\n",
      "7    8  http://financials.morningstar.com/finan/financ...\n",
      "8    9  http://performance.morningstar.com/perform/Per...\n",
      "9   10  http://financials.morningstar.com/ajax/ReportP...\n",
      "10  11  http://financials.morningstar.com/ajax/ReportP...\n",
      "11  12  http://financials.morningstar.com/ajax/ReportP...\n",
      "12  13  http://financials.morningstar.com/ajax/ReportP...\n",
      "13  14  http://financials.morningstar.com/ajax/ReportP...\n",
      "14  15  http://financials.morningstar.com/ajax/ReportP...\n",
      "15  16  http://insiders.morningstar.com/insiders/tradi... \n",
      "here are urls\n",
      "     id security_type_code                             security_type\n",
      "0    1               Code                           Investment Type\n",
      "1    2                 BK                             529 Benchmark\n",
      "2    3                 PG                             529 Peergroup\n",
      "3    4                 CP                                  529 Plan\n",
      "4    5                 CT                             529 Portfolio\n",
      "5    6                 AG                                 Aggregate\n",
      "6    7                 CA                          Category Average\n",
      "7    8                 FC                           Closed-End Fund\n",
      "8    9                 CU                         Currency Exchange\n",
      "9   10                 SP                              Private Fund\n",
      "10  11                 UA                                   Account\n",
      "11  12                 EI                       Economic Indicators\n",
      "12  13                 FE                      Exchange-Traded Fund\n",
      "13  14                 FG                                 Euro Fund\n",
      "14  15                 F0                              Fixed Income\n",
      "15  16                 FH                                Hedge Fund\n",
      "16  17                 H1                            HFR Hedge Fund\n",
      "17  18                 VS               eVestment Separate Accounts\n",
      "18  19                 VH                     eVestment Hedge Funds\n",
      "19  20                 XI                                     Index\n",
      "20  21                 PS       European Pension/Life Fund Wrappers\n",
      "21  22                 FV                    Insurance Product Fund\n",
      "22  23                 PO                              MF Objective\n",
      "23  24                 FM                         Money Market Fund\n",
      "24  25                 FO                             Open-End Fund\n",
      "25  26                 SA                          Separate Account\n",
      "26  27                 ST                                     Stock\n",
      "27  28                 V1                         UK LP SubAccounts\n",
      "28  29                 P1               UK Life and Pension Polices\n",
      "29  30                 FI                     Unit Investment Trust\n",
      "30  31                 VP                                 VA Policy\n",
      "31  32                 VA                             VA Subaccount\n",
      "32  33                 LP                                 VL Policy\n",
      "33  34                 VL                             VL Subaccount\n",
      "34  35                 DF                      Restricted Investors\n",
      "35  36                 IF                             Internal Only\n",
      "36  37                 S1                     UBS Separate Accounts\n",
      "37  38                 PI  Special Pooled Funds for Unregistered VA \n",
      "here are securitytypes\n",
      "              id ticker\n",
      "0             1      A\n",
      "1             2      B\n",
      "2             3      C\n",
      "3             4      D\n",
      "4             5      E\n",
      "...         ...    ...\n",
      "88696  18082638   DP4H\n",
      "88697  18098632  01832\n",
      "88698  18203664   0NFL\n",
      "88699  18203962   0MMR\n",
      "88700  18213771    T9H\n",
      "\n",
      "[88701 rows x 2 columns] \n",
      "here are tickers\n",
      "      id                  sector\n",
      "0     1                       —\n",
      "1     3         Basic Materials\n",
      "2    10              Technology\n",
      "3    14             Industrials\n",
      "4    20      Financial Services\n",
      "5    25              Healthcare\n",
      "6    43  Communication Services\n",
      "7    50       Consumer Cyclical\n",
      "8    59                  Energy\n",
      "9    72             Real Estate\n",
      "10  110      Consumer Defensive\n",
      "11  118               Utilities \n",
      "here are sectors\n",
      "         id                          industry  sector_id\n",
      "0        1                                 —          1\n",
      "1        3               Specialty Chemicals          3\n",
      "2       10             Electronic Components         10\n",
      "3       14               Aerospace & Defense         14\n",
      "4       15        Engineering & Construction         14\n",
      "..     ...                               ...        ...\n",
      "141   4496                           Uranium         59\n",
      "142   4747  Financial Data & Stock Exchanges         20\n",
      "143   5109         Rental & Leasing Services         14\n",
      "144   5902           Financial Conglomerates         20\n",
      "145  11403                  REIT - Specialty         72\n",
      "\n",
      "[146 rows x 3 columns] \n",
      "here are industries\n",
      "         id                                    exchange exchange_sym  \\\n",
      "0        0                                        None         None   \n",
      "1        1                             OTC GREY MARKET         GREY   \n",
      "2       16                          DEUTSCHE BOERSE AG         XFRA   \n",
      "3       17                               BOERSE BERLIN         XBER   \n",
      "4       18                       LONDON STOCK EXCHANGE         XLON   \n",
      "5       25                                 OTC MARKETS         PINX   \n",
      "6       26        HONG KONG EXCHANGES AND CLEARING LTD         XHKG   \n",
      "7       44                                      NASDAQ         XNAS   \n",
      "8      138                                       XETRA         XETR   \n",
      "9      141                             BOERSE MUENCHEN         XMUN   \n",
      "10     142                          BOERSE DUESSELDORF         XDUS   \n",
      "11     143                             BOERSE HANNOVER         XHAN   \n",
      "12     144                            BOERSE STUTTGART         XSTU   \n",
      "13     145                              BOERSE HAMBURG         XHAM   \n",
      "14     302               NEW YORK STOCK EXCHANGE, INC.         XNYS   \n",
      "15     374                                   NYSE ARCA         ARCX   \n",
      "16     433                           ASX - ALL MARKETS         XASX   \n",
      "17     482                             BATS Z-EXCHANGE         BATS   \n",
      "18     547                                NYSE MKT LLC         XASE   \n",
      "19     552           LSE International Trading Service          LTS   \n",
      "20     553                   EURONEXT - EURONEXT PARIS         XPAR   \n",
      "21     563                     SHENZHEN STOCK EXCHANGE         XSHE   \n",
      "22     569                     SHANGHAI STOCK EXCHANGE         XSHG   \n",
      "23     575                       BORSA ITALIANA S.P.A.         XMIL   \n",
      "24     606                           Dow Jones Indices          DJI   \n",
      "25     649                      TORONTO STOCK EXCHANGE         XTSE   \n",
      "26     667                EURONEXT - EURONEXT BRUSSELS         XBRU   \n",
      "27     669                        TSX VENTURE EXCHANGE         XTSX   \n",
      "28    1083                                NEX Exchange         NEXX   \n",
      "29    1530               EURONEXT - EURONEXT AMSTERDAM         XAMS   \n",
      "30    1625                       AEQUITAS NEO EXCHANGE         NEOE   \n",
      "31    1637                  EURONEXT - ALTERNEXT PARIS         ALXP   \n",
      "32    2300                                U.S. Indexes         IXUS   \n",
      "33    2427            CANADIAN NATIONAL STOCK EXCHANGE         XCNQ   \n",
      "34    2735                          SIX SWISS EXCHANGE         XSWX   \n",
      "35    7923                             BOLSA DE MADRID         XMAD   \n",
      "36   20014                                                     OTCM   \n",
      "37   21170                                 S&P Indices          SPI   \n",
      "38   23704           XFMQ--Unlisted Fund Manager Quote         $$$$   \n",
      "39   30117                        TOKYO STOCK EXCHANGE         XTKS   \n",
      "40   34500                                               CU$$$$$USD   \n",
      "41   58438                  EURONEXT - EURONEXT LISBON         XLIS   \n",
      "42   97057                              U.S. Composite         USCO   \n",
      "43  104067                          SINGAPORE EXCHANGE         XSES   \n",
      "44  138753                     NASDAQ OMX STOCKHOLM AB         XSTO   \n",
      "45  142140                         CBOE STOCK EXCHANGE         CBSX   \n",
      "46  157976                          Investors Exchange         IEXG   \n",
      "47  174590           IRISH STOCK EXCHANGE - ALL MARKET         XDUB   \n",
      "48  210421                    C2 OPTIONS EXCHANGE INC.         C2OX   \n",
      "49  230677     SIX SWISS EXCHANGE - BLUE CHIPS SEGMENT         XVTX   \n",
      "50  416377                                       OTCBB         XOTC   \n",
      "51  497136                   NASDAQ OMX COPENHAGEN A/S         XCSE   \n",
      "52  501001                   LUXEMBOURG STOCK EXCHANGE         XLUX   \n",
      "53  508599                               OSLO BORS ASA         XOSL   \n",
      "54  532447                   Global Indices Feed (GIF)          GIF   \n",
      "55  587320                             NASDAQ OMX PHLX         XPHL   \n",
      "56  601770                    NASDAQ OMX HELSINKI LTD.         XHEL   \n",
      "57  608212                           EUREX DEUTSCHLAND         XEUR   \n",
      "58  646159  WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET         XWAR   \n",
      "\n",
      "    country_id  \n",
      "0          NaN  \n",
      "1        235.0  \n",
      "2         82.0  \n",
      "3         82.0  \n",
      "4        234.0  \n",
      "5        235.0  \n",
      "6         99.0  \n",
      "7        235.0  \n",
      "8         82.0  \n",
      "9         82.0  \n",
      "10        82.0  \n",
      "11        82.0  \n",
      "12        82.0  \n",
      "13        82.0  \n",
      "14       235.0  \n",
      "15       235.0  \n",
      "16        13.0  \n",
      "17       235.0  \n",
      "18       235.0  \n",
      "19       234.0  \n",
      "20       129.0  \n",
      "21        45.0  \n",
      "22        45.0  \n",
      "23       109.0  \n",
      "24       235.0  \n",
      "25        39.0  \n",
      "26        21.0  \n",
      "27        39.0  \n",
      "28       234.0  \n",
      "29       156.0  \n",
      "30        39.0  \n",
      "31       129.0  \n",
      "32       235.0  \n",
      "33        39.0  \n",
      "34       129.0  \n",
      "35       208.0  \n",
      "36       235.0  \n",
      "37       235.0  \n",
      "38       235.0  \n",
      "39       156.0  \n",
      "40       235.0  \n",
      "41       177.0  \n",
      "42       235.0  \n",
      "43       129.0  \n",
      "44       214.0  \n",
      "45       235.0  \n",
      "46       235.0  \n",
      "47       106.0  \n",
      "48        82.0  \n",
      "49       129.0  \n",
      "50       235.0  \n",
      "51       235.0  \n",
      "52       129.0  \n",
      "53       165.0  \n",
      "54       235.0  \n",
      "55       235.0  \n",
      "56        74.0  \n",
      "57       235.0  \n",
      "58       129.0   \n",
      "here are exchanges\n",
      "       id            country country_c2 country_c3\n",
      "0      1        Afghanistan         AF        AFG\n",
      "1      2            Albania         AL        ALB\n",
      "2      3            Algeria         DZ        DZA\n",
      "3      4     American Samoa         AS        ASM\n",
      "4      5            Andorra         AD        AND\n",
      "..   ...                ...        ...        ...\n",
      "243  244  Wallis and Futuna         WF        WLF\n",
      "244  245     Western Sahara         EH        ESH\n",
      "245  246              Yemen         YE        YEM\n",
      "246  247             Zambia         ZM        ZMB\n",
      "247  248           Zimbabwe         ZW        ZWE\n",
      "\n",
      "[248 rows x 4 columns] \n",
      "here are countries\n",
      " Empty DataFrame\n",
      "Columns: [id, company]\n",
      "Index: [] \n",
      "here are companies\n",
      "       id             currency currency_code\n",
      "0      1          Albania Lek           ALL\n",
      "1      2  Afghanistan Afghani           AFN\n",
      "2      3       Argentina Peso           ARS\n",
      "3      4        Aruba Guilder           AWG\n",
      "4      5     Australia Dollar           AUD\n",
      "..   ...                  ...           ...\n",
      "106  107    Venezuela Bolívar           VEF\n",
      "107  108        Viet Nam Dong           VND\n",
      "108  109           Yemen Rial           YER\n",
      "109  110      Zimbabwe Dollar           ZWD\n",
      "110  349                 None           GBX\n",
      "\n",
      "[111 rows x 3 columns] \n",
      "here are currencies\n",
      "      id          stock_type\n",
      "0     1                   —\n",
      "1     2          Distressed\n",
      "2    14            Cyclical\n",
      "3    22         Slow Growth\n",
      "4    25  Speculative Growth\n",
      "5    59          Hard Asset\n",
      "6  1119          High Yield\n",
      "7  1151   Aggressive Growth\n",
      "8  1297      Classic Growth \n",
      "here are stocktype\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dataframes.DataFrames at 0x108b45b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Master DataFrame instance from reference tables\n",
    "Merge `df.master` (*Master* bridge table) with other reference tables (e.g. `df.tickers`, `df.exchanges`, etc.) and filter out inactive / invalid records.\n",
    "### DataFrame Instance\n",
    "Create `df_master`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.662709Z",
     "start_time": "2025-05-20T05:20:03.690954Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming these DataFrames are already defined in your script\n",
    "# df.urls, df.securitytypes, df.tickers, df.sectors, df.industries, df.stockstyles\n",
    "# df.exchanges, df.countries, df.companies, df.currencies, df.stocktypes\n",
    "\n",
    "# Perform sequential merges on a common key (assuming 'ticker_id' is the shared key)\n",
    "\n",
    "# Step 1: Merge df.urls with df.securitytypes on 'ticker_id'\n",
    "df_master = pd.merge(df.urls, df.securitytypes, on='id', how='left')\n",
    "\n",
    "# Step 2: Merge df_master with df.tickers\n",
    "df_master = pd.merge(df_master, df.tickers, on='ticker_id', how='left')\n",
    "\n",
    "# Step 3: Merge with df.sectors\n",
    "# df_master = pd.merge(df_master, df.sectors, on='ticker_id', how='left')\n",
    "\n",
    "# Step 4: Merge with df.industries\n",
    "df_master = pd.merge(df_master, df.industries, on='ticker_id', how='left')\n",
    "\n",
    "# Step 5: Merge with df.stockstyles\n",
    "# df_master = pd.merge(df_master, df.stockstyles, on='ticker_id', how='left')\n",
    "\n",
    "# Step 6: Merge with df.exchanges\n",
    "##df_master = pd.merge(df_master, df.exchanges, on='ticker_id', how='left')\n",
    "\n",
    "# Step 7: Merge with df.countries\n",
    "df_master = pd.merge(df_master, df.countries, on='ticker_id', how='left')\n",
    "\n",
    "# Step 8: Merge with df.companies\n",
    "df_master = pd.merge(df_master, df.companies, on='ticker_id', how='left')\n",
    "\n",
    "# Step 9: Merge with df.currencies\n",
    "## df_master = pd.merge(df_master, df.currencies, on='ticker_id', how='left')\n",
    "\n",
    "# Step 10: Merge with df.stocktypes\n",
    "df_master = pd.merge(df_master, df.stocktypes, on='ticker_id', how='left')\n",
    "\n",
    "# Now df_master contains all the combined information\n",
    "print(df_master.head())\n",
    "\n",
    "# Optionally, save the merged DataFrame to a CSV file or a new SQLite database\n",
    "df_master.to_csv('merged_data.csv', index=False)\n",
    "# Or to SQLite\n",
    "# df_master.to_sql('master_table', conn, if_exists='replace', index=False)\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 10\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Assuming these DataFrames are already defined in your script\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# df.urls, df.securitytypes, df.tickers, df.sectors, df.industries, df.stockstyles\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# df.exchanges, df.countries, df.companies, df.currencies, df.stocktypes\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      8\u001B[0m \n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Step 1: Merge df.urls with df.securitytypes on 'ticker_id'\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m df_master \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(df\u001B[38;5;241m.\u001B[39murls, df\u001B[38;5;241m.\u001B[39msecuritytypes, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Step 2: Merge df_master with df.tickers\u001B[39;00m\n\u001B[1;32m     13\u001B[0m df_master \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(df_master, df\u001B[38;5;241m.\u001B[39mtickers, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mticker_id\u001B[39m\u001B[38;5;124m'\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_master_copy = df.master.copy()\n",
    "df_master_copy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.676043Z",
     "start_time": "2024-09-10T03:41:02.516364Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DT.date.today()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.683921Z",
     "start_time": "2024-09-10T03:41:02.519677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DT.datetime(2024,month=10,day=9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.684303Z",
     "start_time": "2024-09-10T03:41:02.523007Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the following filter:\n",
    "<br>\n",
    "- $lastdate < cutoff\\_date$\n",
    "<br>\n",
    "- $cutoff\\_date = date one\\ week\\ prior\\ to\\ last\\ date\\ the\\ database\\ was\\ updated$\n",
    "<br>\n",
    "<br>\n",
    "This filter ensure that only active records are included in the master dataframe, excluding inactive MorningStar records which are no longer being updated on a regular basis. These inactive records are typically symbols that are no longer active in their exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "cutoff_days = 10\n",
    "df_updated_ct = df_master[['update_date', 'ticker']].groupby('update_date').count().sort_index()\n",
    "cutoff_date = df_updated_ct[df_updated_ct['ticker'] > 100].index[0] # - DT.timedelta(days=cutoff_days)\n",
    "\n",
    "df_master = df_master.where(df_master['lastdate'] >= cutoff_date).dropna(axis=0, how='all')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cutoff_days = 1\n",
    "df_updated_ct = df_master[['update_date', 'ticker']].groupby('update_date').count().sort_index()\n",
    "cutoff_date = df_updated_ct[df_updated_ct['ticker'] > 100].index[0] # - DT.timedelta(days=cutoff_days)\n",
    "\n",
    "df_master = df_master.where(df_master['lastdate'] >= cutoff_date).dropna(axis=0, how='all')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.684533Z",
     "start_time": "2024-09-10T03:41:02.526369Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_master"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.684779Z",
     "start_time": "2024-09-10T03:41:02.529763Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.685091Z",
     "start_time": "2024-09-10T03:41:02.533181Z"
    }
   },
   "outputs": [],
   "source": [
    "msg = 'DataFrame df_master contains {:,.0f} records and {:,.0f} columns.'\n",
    "print(msg.format(df_master.shape[0], df_master.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.685397Z",
     "start_time": "2024-09-10T03:41:02.536577Z"
    }
   },
   "outputs": [],
   "source": [
    "df_master.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "[return to the top](#top)\n",
    "<a id='methods'></a>\n",
    "# Creating DataFrame instances with dataframes methods\n",
    "Class DataFrames from [dataframe.py](dataframe.py) contains the following methods that return a pd.DataFrame object for the specified database table:\n",
    "\n",
    "- `quoteheader` - [MorningStar (MS) Quote Header](#quote)\n",
    "- `valuation` - [MS Valuation table with Price Ratios (P/E, P/S, P/B, P/C) for the past 10 yrs](#val)\n",
    "- `keyratios` - [MS Ratio - Key Financial Ratios & Values](#keyratios)\n",
    "- `finhealth` - [MS Ratio - Financial Health](#finhealth)\n",
    "- `profitability` - [MS Ratio - Profitability](#prof)\n",
    "- `growth` - [MS Ratio - Growth](#growth)\n",
    "- `cfhealth` - [MS Ratio - Cash Flow Health](#cfh)\n",
    "- `efficiency` - [MS Ratio - Efficiency](#eff)\n",
    "- `annualIS` - [MS Annual Income Statements](#isa)\n",
    "- `quarterlyIS` - [MS Quarterly Income Statements](#isq)\n",
    "- `annualBS` - [MS Annual Balance Sheets](#bsa)\n",
    "- `quarterlyBS` - [MS Quarterly Balance Sheets](#bsq)\n",
    "- `annualCF` - [MS Annual Cash Flow Statements](#cfa)\n",
    "- `quarterlyCF` - [MS Quarterly Cash Flow Statements](#cfq)\n",
    "- `insider_trades` - [Insider Transactions](#it)\n",
    "\n",
    "<a id='quote'></a>\n",
    "### Quote Header\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.685704Z",
     "start_time": "2024-09-10T03:41:02.539877Z"
    }
   },
   "outputs": [],
   "source": [
    "df_quote = df.quoteheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.685962Z",
     "start_time": "2024-09-10T03:41:02.543389Z"
    }
   },
   "outputs": [],
   "source": [
    "df_quote.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.686204Z",
     "start_time": "2024-09-10T03:41:02.547007Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_quote)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='val'></a>\n",
    "[return to the top](#top)\n",
    "### Price Ratios (P/E, P/S, P/B, P/C)\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.686470Z",
     "start_time": "2024-09-10T03:41:02.550418Z"
    }
   },
   "outputs": [],
   "source": [
    "df_vals = df.valuation().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.686722Z",
     "start_time": "2024-09-10T03:41:02.553946Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.687024Z",
     "start_time": "2024-09-10T03:41:02.557273Z"
    }
   },
   "outputs": [],
   "source": [
    "df_vals.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='keyratios'></a>\n",
    "[return to the top](#top)\n",
    "### Key Ratios\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.687300Z",
     "start_time": "2024-09-10T03:41:02.560590Z"
    }
   },
   "outputs": [],
   "source": [
    "df_keyratios = df.keyratios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.687760Z",
     "start_time": "2024-09-10T03:41:02.564023Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_keyratios)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.688104Z",
     "start_time": "2024-09-10T03:41:02.567636Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_keyratios = (df_keyratios\n",
    "                     .loc[0, [col for col in df_keyratios.columns if 'Y' not in col and col.startswith('i')]]\n",
    "                     .replace(df.colheaders['header']))\n",
    "df_labels_keyratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='finhealth'></a>\n",
    "[return to the top](#top)\n",
    "### Financial Health\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.688346Z",
     "start_time": "2024-09-10T03:41:02.570884Z"
    }
   },
   "outputs": [],
   "source": [
    "df_finhealth = df.finhealth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.688581Z",
     "start_time": "2024-09-10T03:41:02.574270Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_finhealth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.688855Z",
     "start_time": "2024-09-10T03:41:02.577674Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_finhealth = (df_finhealth.loc[0, [col for col in df_finhealth.columns\n",
    "                                          if 'Y' not in col and '_id' not in col]]\n",
    "                     .replace(df.colheaders['header']))\n",
    "df_labels_finhealth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prof'></a>\n",
    "[return to the top](#top)\n",
    "### Profitability\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.689080Z",
     "start_time": "2024-09-10T03:41:02.580999Z"
    }
   },
   "outputs": [],
   "source": [
    "df_profitab = df.profitability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.689343Z",
     "start_time": "2024-09-10T03:41:02.584474Z"
    }
   },
   "outputs": [],
   "source": [
    "df_profitab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.689566Z",
     "start_time": "2024-09-10T03:41:02.587957Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_profitab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.689811Z",
     "start_time": "2024-09-10T03:41:02.591280Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_profitab = (df_profitab.loc[0, [col for col in df_profitab.columns if 'Y' not in col and '_id' not in col]]\n",
    "                    .replace(df.colheaders['header']))\n",
    "df_labels_profitab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='growth'></a>\n",
    "[return to the top](#top)\n",
    "### Growth\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.690074Z",
     "start_time": "2024-09-10T03:41:02.594930Z"
    }
   },
   "outputs": [],
   "source": [
    "df_growth = df.growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.690322Z",
     "start_time": "2024-09-10T03:41:02.598344Z"
    }
   },
   "outputs": [],
   "source": [
    "df_growth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.690596Z",
     "start_time": "2024-09-10T03:41:02.601804Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_growth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.690871Z",
     "start_time": "2024-09-10T03:41:02.605334Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_growth = (df_growth.loc[0, [col for col in df_growth.columns\n",
    "                                      if 'Y' not in col and '_id' not in col]].replace(df.colheaders['header']))\n",
    "df_labels_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cfh'></a>\n",
    "[return to the top](#top)\n",
    "### Cash Flow Health\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.691121Z",
     "start_time": "2024-09-10T03:41:02.608703Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cfhealth = df.cfhealth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.691515Z",
     "start_time": "2024-09-10T03:41:02.612062Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cfhealth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.692974Z",
     "start_time": "2024-09-10T03:41:02.615179Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_cfhealth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.694092Z",
     "start_time": "2024-09-10T03:41:02.618599Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_cfhealth = df_cfhealth.loc[0, [col for col in df_cfhealth.columns if 'Y' not in col\n",
    "                                         and '_id' not in col]].replace(df.colheaders['header'])\n",
    "df_labels_cfhealth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eff'></a>\n",
    "[return to the top](#top)\n",
    "### Efficiency\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.694366Z",
     "start_time": "2024-09-10T03:41:02.621910Z"
    }
   },
   "outputs": [],
   "source": [
    "df_efficiency = df.efficiency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.694750Z",
     "start_time": "2024-09-10T03:41:02.625277Z"
    }
   },
   "outputs": [],
   "source": [
    "df_efficiency.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.694995Z",
     "start_time": "2024-09-10T03:41:02.628573Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_efficiency)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.695227Z",
     "start_time": "2024-09-10T03:41:02.632062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Financial Health DataFrame Columns\n",
    "(df_efficiency.loc[0, [col for col in df_efficiency.columns if 'Y' not in col and '_id' not in col]]\n",
    " .replace(df.colheaders['header']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='isa'></a>\n",
    "[return to the top](#top)\n",
    "### Annual Income Statement\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.695465Z",
     "start_time": "2024-09-10T03:41:02.635557Z"
    }
   },
   "outputs": [],
   "source": [
    "df_annualIS = df.annualIS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.695693Z",
     "start_time": "2024-09-10T03:41:02.639041Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_annualIS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.695908Z",
     "start_time": "2024-09-10T03:41:02.642418Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [col for col in df_annualIS if 'label' in col]\n",
    "labels = [[label, header] for label in labels\n",
    "          for header in df_annualIS[label].unique().tolist() if pd.notna(header)]\n",
    "\n",
    "df_labels_aIS = (pd.DataFrame(labels, columns=['header', 'value']).set_index('header').astype('int'))\n",
    "df_labels_aIS['value'] = df_labels_aIS['value'].replace(df.colheaders['header'])\n",
    "df_labels_aIS[df_labels_aIS['value'].astype('str').str.contains('ncome')].sort_values(by='value')\n",
    "\n",
    "sorted(list(zip(df_labels_aIS.values.tolist(), df_labels_aIS.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='isq'></a>\n",
    "[return to the top](#top)\n",
    "### Quarterly Income Statements\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.696145Z",
     "start_time": "2024-09-10T03:41:02.645950Z"
    }
   },
   "outputs": [],
   "source": [
    "df_quarterlyIS = df.quarterlyIS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.696388Z",
     "start_time": "2024-09-10T03:41:02.649343Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_quarterlyIS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.697627Z",
     "start_time": "2024-09-10T03:41:02.652823Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [col for col in df_annualIS if 'label' in col]\n",
    "labels = [[label, header] for label in labels\n",
    "          for header in df_annualIS[label].unique().tolist() if pd.notna(header)]\n",
    "\n",
    "df_labels_aIS = (pd.DataFrame(labels, columns=['header', 'value']).set_index('header').astype('int'))\n",
    "df_labels_aIS['value'] = df_labels_aIS['value'].replace(df.colheaders['header'])\n",
    "df_labels_aIS[df_labels_aIS['value'].astype('str').str.contains('ncome')].sort_values(by='value')\n",
    "\n",
    "sorted(list(zip(df_labels_aIS.values.tolist(), df_labels_aIS.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bsa'></a>\n",
    "[return to the top](#top)\n",
    "### Annual Balance Sheet\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.697927Z",
     "start_time": "2024-09-10T03:41:02.656444Z"
    }
   },
   "outputs": [],
   "source": [
    "df_annualBS = df.annualBS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.698181Z",
     "start_time": "2024-09-10T03:41:02.659769Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_annualBS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.698409Z",
     "start_time": "2024-09-10T03:41:02.663136Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [col for col in df_annualBS if 'label' in col]\n",
    "labels = [[label, header] for label in labels\n",
    "          for header in df_annualBS[label].unique().tolist() if pd.notna(header)]\n",
    "\n",
    "df_labels_aBS = (pd.DataFrame(labels, columns=['header', 'value']).set_index('header').astype('int'))\n",
    "df_labels_aBS['value'] = df_labels_aBS['value'].replace(df.colheaders['header'])\n",
    "df_labels_aBS[df_labels_aBS['value'].astype('str').str.contains('ncome')].sort_values(by='value')\n",
    "\n",
    "sorted(list(zip(df_labels_aBS.values.tolist(), df_labels_aBS.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bsq'></a>\n",
    "[return to the top](#top)\n",
    "### Quarterly Balance Sheet\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.698633Z",
     "start_time": "2024-09-10T03:41:02.666617Z"
    }
   },
   "outputs": [],
   "source": [
    "df_quarterlyBS = df.quarterlyBS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.700311Z",
     "start_time": "2024-09-10T03:41:02.669913Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_quarterlyBS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.700653Z",
     "start_time": "2024-09-10T03:41:02.673305Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [col for col in df_quarterlyBS if 'label' in col]\n",
    "labels = [[label, header] for label in labels\n",
    "          for header in df_quarterlyBS[label].unique().tolist() if pd.notna(header)]\n",
    "\n",
    "df_labels_qBS = (pd.DataFrame(labels, columns=['header', 'value']).set_index('header').astype('int'))\n",
    "df_labels_qBS['value'] = df_labels_qBS['value'].replace(df.colheaders['header'])\n",
    "df_labels_qBS[df_labels_qBS['value'].astype('str').str.contains('ncome')].sort_values(by='value')\n",
    "\n",
    "sorted(list(zip(df_labels_qBS.values.tolist(), df_labels_qBS.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cfa'></a>\n",
    "[return to the top](#top)\n",
    "### Annual Cash Flow Statement\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.700961Z",
     "start_time": "2024-09-10T03:41:02.676736Z"
    }
   },
   "outputs": [],
   "source": [
    "df_annualCF = df.annualCF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.701192Z",
     "start_time": "2024-09-10T03:41:02.680135Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_annualCF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.701437Z",
     "start_time": "2024-09-10T03:41:02.683475Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [col for col in df_annualCF if 'label' in col]\n",
    "labels = [[label, header] for label in labels\n",
    "          for header in df_annualCF[label].unique().tolist() if pd.notna(header)]\n",
    "\n",
    "df_labels_aCF = (pd.DataFrame(labels, columns=['header', 'value']).set_index('header').astype('int'))\n",
    "df_labels_aCF['value'] = df_labels_aCF['value'].replace(df.colheaders['header'])\n",
    "df_labels_aCF[df_labels_aCF['value'].astype('str').str.contains('ncome')].sort_values(by='value')\n",
    "\n",
    "sorted(list(zip(df_labels_aCF.values.tolist(), df_labels_aCF.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cfq'></a>\n",
    "[return to the top](#top)\n",
    "### Quarterly Cash Flow Statement\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.701680Z",
     "start_time": "2024-09-10T03:41:02.686866Z"
    }
   },
   "outputs": [],
   "source": [
    "df_quarterlyCF = df.quarterlyCF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.701922Z",
     "start_time": "2024-09-10T03:41:02.690230Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_quarterlyCF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.703642Z",
     "start_time": "2024-09-10T03:41:02.693561Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [col for col in df_quarterlyCF if 'label' in col]\n",
    "labels = [[label, header] for label in labels\n",
    "          for header in df_quarterlyCF[label].unique().tolist() if pd.notna(header)]\n",
    "\n",
    "df_labels_qCF = (pd.DataFrame(labels, columns=['header', 'value']).set_index('header').astype('int'))\n",
    "df_labels_qCF['value'] = df_labels_qCF['value'].replace(df.colheaders['header'])\n",
    "df_labels_qCF[df_labels_qCF['value'].astype('str').str.contains('ncome')].sort_values(by='value')\n",
    "\n",
    "sorted(list(zip(df_labels_qCF.values.tolist(), df_labels_qCF.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='it'></a>\n",
    "[return to the top](#top)\n",
    "### Insider Transactions\n",
    "##### DataFrame Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.703896Z",
     "start_time": "2024-09-10T03:41:02.696860Z"
    }
   },
   "outputs": [],
   "source": [
    "df_insidertrades = df.insider_trades()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.704123Z",
     "start_time": "2024-09-10T03:41:02.700261Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame contains {:,.0f} records.'.format(len(df_insidertrades)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stats\"></a>\n",
    "[return to the top](#top)\n",
    "# Performing statistical analysis\n",
    "### Count of database records\n",
    "**1.** Total number of records **before** merging reference tables (length of `df.master0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.704361Z",
     "start_time": "2024-09-10T03:41:02.703679Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame df.master contains {:,.0f} records.'.format(len(df.master0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Total number of records **after** merging reference tables (length of `df.master`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.704578Z",
     "start_time": "2024-09-10T03:41:02.707049Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame df_master0 contains {:,.0f} records.'.format(len(df.master)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Total number of records **after** filtering out inactive records (length of `df_master`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.704794Z",
     "start_time": "2024-09-10T03:41:02.709393Z"
    }
   },
   "outputs": [],
   "source": [
    "print('DataFrame df_master contains {:,.0f} records.'.format(len(df_master)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lastupdate\"></a>\n",
    "[return to the top](#top)\n",
    "### Last updated dates\n",
    "List of dates (as a pd.Series object) of when the database records were last updated.\n",
    "The values indicate the number of records updated on each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.705101Z",
     "start_time": "2024-09-10T03:41:02.711826Z"
    }
   },
   "outputs": [],
   "source": [
    "(df_master[['update_date', 'ticker']].groupby(by='update_date').count().sort_index(ascending=False)\n",
    " .rename(columns={'ticker':'ticker_count'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"type\"></a>\n",
    "[return to the top](#top)\n",
    "### Number of records by Security Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.705333Z",
     "start_time": "2024-09-10T03:41:02.714239Z"
    }
   },
   "outputs": [],
   "source": [
    "(df_master[['security_type', 'ticker']].groupby(by='security_type').count()\n",
    " .rename(columns={'ticker':'ticker_count'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"country\"></a>\n",
    "[return to the top](#top)\n",
    "### Number of records by Country, based on the location of exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.705557Z",
     "start_time": "2024-09-10T03:41:02.716547Z"
    }
   },
   "outputs": [],
   "source": [
    "(df_master[['country', 'country_c3', 'ticker']]\n",
    " .groupby(by=['country', 'country_c3']).count().rename(columns={'ticker':'ticker_count'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exchange\"></a>\n",
    "[return to the top](#top)\n",
    "### Number of records per exchange\n",
    "Where $ticker\\_count > 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.705814Z",
     "start_time": "2024-09-10T03:41:02.719048Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['country', 'country_c3', 'exchange', 'exchange_sym', 'ticker']\n",
    "df_exchanges = df_master[cols].groupby(by=cols[:-1]).count().rename(columns={'ticker':'ticker_count'})\n",
    "df_exchanges[df_exchanges['ticker_count'] > 100].sort_values(by='ticker_count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[return to the top](#top)\n",
    "### Number of Stocks by Country of Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.706030Z",
     "start_time": "2024-09-10T03:41:02.721442Z"
    }
   },
   "outputs": [],
   "source": [
    "(df_master\n",
    " .where(df_master['security_type'] == 'Stock').dropna(axis=0, how='all')[['country', 'country_c3', 'ticker']]\n",
    " .groupby(by=['country', 'country_c3']).count().rename(columns={'ticker':'ticker_count'})\n",
    " .sort_values(by='ticker_count', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sector\"></a>\n",
    "[return to the top](#top)\n",
    "### Number of stocks by sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.706246Z",
     "start_time": "2024-09-10T03:41:02.723797Z"
    }
   },
   "outputs": [],
   "source": [
    "(df_master\n",
    " .where((df_master['security_type'] == 'Stock') & (df_master['sector'] != '—')).dropna(axis=0, how='all')\n",
    " .groupby(by='sector').count()\n",
    " .rename(columns={'ticker':'stock_count'}))['stock_count'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"industry\"></a>\n",
    "[return to the top](#top)\n",
    "### Number of stocks by industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.706458Z",
     "start_time": "2024-09-10T03:41:02.726069Z"
    }
   },
   "outputs": [],
   "source": [
    "(df_master[['sector', 'industry', 'ticker']]\n",
    " .where((df_master['security_type'] == 'Stock') & (df_master['industry'] != '—')).dropna(axis=0, how='all')\n",
    " .groupby(by=['sector', 'industry']).count().rename(columns={'ticker':'stock_count'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"meanpr\"></a>\n",
    "[return to the top](#top)\n",
    "### Mean price ratios (P/E, P/S, P/B, P/CF) of stocks by sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, merge `df_master` and `df_vals` and remove outliers where Price Ratio > 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.706710Z",
     "start_time": "2024-09-10T03:41:02.728363Z"
    }
   },
   "outputs": [],
   "source": [
    "df_valuation = (df_master\n",
    "                .where((df_master['security_type'] == 'Stock') & (df_master['sector'] != '—'))\n",
    "                .dropna(axis=0, how='all')\n",
    "                .merge(df_vals, on=['ticker_id', 'exchange_id'])\n",
    "                .drop(['ticker_id', 'exchange_id'], axis=1))\n",
    "\n",
    "cols = list(filter(lambda col: col.startswith('P'), df_valuation))\n",
    "df0 = df_valuation.copy()\n",
    "for col in cols:\n",
    "    df0 = df[(df[col] < 10000) | df[col].isna()]\n",
    "print('There are {:,.0f} Stock records that fit this criteria.'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean TTM Price Ratios for all stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.706940Z",
     "start_time": "2024-09-10T03:41:02.730687Z"
    }
   },
   "outputs": [],
   "source": [
    "df_val_mean = (df[['sector', 'company']].groupby('sector').count()\n",
    "               .rename(columns={'company':'count'})\n",
    "               .merge(df.groupby('sector').mean().round(4), on='sector')\n",
    "               .sort_values(by='PE_TTM', ascending=False))\n",
    "\n",
    "df_val_mean[['count', 'PE_Forward', 'PE_TTM', 'PB_TTM', 'PS_TTM', 'PC_TTM']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean TTM Price Ratios for USA stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.707198Z",
     "start_time": "2024-09-10T03:41:02.732985Z"
    }
   },
   "outputs": [],
   "source": [
    "df_valuation_USA = df[df['country_c3'] == 'USA']\n",
    "print('There are {:,.0f} Stock records that fit this criteria.'.format(len(df_valuation_USA)))\n",
    "\n",
    "df_val_mean_USA = (df_valuation_USA[['sector', 'company']].groupby('sector').count()\n",
    "                   .rename(columns={'company':'count'})\n",
    "                   .merge(df_valuation_USA.groupby('sector').mean().round(4), on='sector')\n",
    "                   .sort_values(by='PE_TTM', ascending=False))\n",
    "\n",
    "df_val_mean_USA[['count', 'PE_Forward', 'PE_TTM', 'PB_TTM', 'PS_TTM', 'PC_TTM']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean TTM Price Ratios for DEU (Germany) stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.707521Z",
     "start_time": "2024-09-10T03:41:02.735460Z"
    }
   },
   "outputs": [],
   "source": [
    "df_valuation_DEU = df[df['country_c3'] == 'DEU']\n",
    "print('There are {:,.0f} Stock records that fit this criteria.'.format(len(df_valuation_DEU)))\n",
    "\n",
    "df_val_mean_DEU = (df_valuation_DEU[['sector', 'company']].groupby('sector').count()\n",
    "                   .rename(columns={'company':'count'})\n",
    "                   .merge(df_valuation_DEU.groupby('sector').mean().round(4), on='sector')\n",
    "                   .sort_values(by='PE_TTM', ascending=False))\n",
    "\n",
    "df_val_mean_DEU[['count', 'PE_Forward', 'PE_TTM', 'PB_TTM', 'PS_TTM', 'PC_TTM']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean TTM Price Ratios for S&P 500 stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.707798Z",
     "start_time": "2024-09-10T03:41:02.737883Z"
    }
   },
   "outputs": [],
   "source": [
    "url = r'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "tables = pd.read_html(url)\n",
    "df_sp500 = tables[0]\n",
    "df_sp500.columns = df_sp500.iloc[0]\n",
    "df_sp500 = df_sp500.drop(0, axis=0).set_index('Symbol').join(df.set_index('ticker'))\n",
    "df_sp500 = df_sp500[df_sp500['country_c3'] == 'USA'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.708064Z",
     "start_time": "2024-09-10T03:41:02.740401Z"
    }
   },
   "outputs": [],
   "source": [
    "print('There are {:,.0f} Stock records that fit this criteria.'.format(len(df_sp500)))\n",
    "\n",
    "df_val_mean_sp500 = (df_sp500[['sector', 'company']].groupby('sector').count()\n",
    "                     .rename(columns={'company':'count'})\n",
    "                     .merge(df_sp500.groupby('sector').mean().round(4), on='sector')\n",
    "                     .sort_values(by='PE_TTM', ascending=False))\n",
    "\n",
    "df_val_mean_sp500[['count', 'PE_Forward', 'PE_TTM', 'PB_TTM', 'PS_TTM', 'PC_TTM']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to the top](#top)\n",
    "#### Plot of TTM P/E by Sectors\n",
    "*All Stocks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.708299Z",
     "start_time": "2024-09-10T03:41:02.742677Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_pe, (ax_pe, ax_pe_usa, ax_pe_deu) = plt.subplots(3, 1, sharex=True, sharey=True, figsize=(8, 6))\n",
    "\n",
    "# All Stocks\n",
    "pe = df_val_mean['PE_TTM']\n",
    "x = [x*3 for x in range(len(pe))]\n",
    "y = pe\n",
    "bars = ax_pe.bar(x, y, width=2)\n",
    "for bar in bars:\n",
    "    ax_pe.text(bar.get_x()+1, bar.get_height()+1.5, '{:.1f}'.format(bar.get_height()),\n",
    "               color='black', ha='center', fontsize=9)\n",
    "ax_pe.get_children()[22].set_color(None)\n",
    "ax_pe.get_children()[23].set_color(None)\n",
    "ax_pe.get_children()[25].set_color(None)\n",
    "ax_pe.set_title('All Stocks', loc='left', fontsize=9, fontweight='bold')\n",
    "\n",
    "# USA\n",
    "pe_usa = df_val_mean_USA['PE_TTM']\n",
    "x = [x*3 for x in range(len(pe_usa))]\n",
    "y = pe_usa\n",
    "bars = ax_pe_usa.bar(x, y, width=2)\n",
    "for bar in bars:\n",
    "    ax_pe_usa.text(bar.get_x()+1, bar.get_height()+1.5, '{:.1f}'.format(bar.get_height()),\n",
    "                   color='black', ha='center', fontsize=9)\n",
    "ax_pe_usa.get_children()[22].set_color(None)\n",
    "ax_pe_usa.get_children()[23].set_color(None)\n",
    "ax_pe_usa.get_children()[25].set_color(None)\n",
    "ax_pe_usa.set_title('USA', loc='left', fontsize=9, fontweight='bold')\n",
    "\n",
    "# DEU\n",
    "pe_deu = df_val_mean_DEU['PE_TTM']\n",
    "x = [x*3 for x in range(len(pe_deu))]\n",
    "y = pe_deu\n",
    "bars = ax_pe_deu.bar(x, y, width=2)\n",
    "for bar in bars:\n",
    "    ax_pe_deu.text(bar.get_x()+1, bar.get_height()+1.5, '{:.1f}'.format(bar.get_height()),\n",
    "                   color='black', ha='center', fontsize=9)\n",
    "ax_pe_deu.get_children()[22].set_color(None)\n",
    "ax_pe_deu.get_children()[23].set_color(None)\n",
    "ax_pe_deu.get_children()[25].set_color(None)\n",
    "ax_pe_deu.set_title('DEU', loc='left', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Plot adjustments\n",
    "plt.xticks(ticks=x, labels=y.index.tolist(), fontsize=9)\n",
    "plt.axis([-3, len(x)*3, 0, 100])\n",
    "plt.suptitle('Average TTM P/E of Stocks by Sector for key regions', fontsize=11, fontweight='bold')\n",
    "plt.yticks([])\n",
    "plt.subplots_adjust(bottom=0.3, hspace=1)\n",
    "\n",
    "for tick in ax_pe_deu.xaxis.get_ticklabels():\n",
    "    tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to the top](#top)\n",
    "#### P/E by Sector for past 10 yrs for US Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.708567Z",
     "start_time": "2024-09-10T03:41:02.745013Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = list(filter(lambda col: col.startswith('PE_'), df.columns))[1:]\n",
    "\n",
    "fig, axs = plt.subplots(11, 1, figsize=(7, 6), sharex=True)\n",
    "sectors = df_val_mean_USA.index.values\n",
    "x = list(range(11))\n",
    "\n",
    "for sector, ax in zip(sectors, axs):\n",
    "    y = df_val_mean_USA[cols].loc[sector].values\n",
    "    p0 = ax.bar(x, y, width=0.5)\n",
    "    #ax.set_title(sector, loc='left', fontsize=9, fontweight='bold')\n",
    "    ax.spines['left'].set_color(None)\n",
    "    ax.spines['right'].set_color(None)\n",
    "    ax.spines['top'].set_color(None)\n",
    "    for pt in list(zip(x, y)):\n",
    "        if pt[1] > 0:\n",
    "            ax.text(pt[0], pt[1] + max(y)*0.05, '{:.0f}'.format(pt[1]), ha='center', fontsize=8)\n",
    "    ax.set_yticks([])\n",
    "    ax.axis([-5.5, 11, 0, max(y)+10])\n",
    "    ax.set_xlim(-5.5, 11)\n",
    "    ax.text(-5.5, max(y)+10, sector, fontweight='bold', fontsize=8)\n",
    "    ax0 = ax\n",
    "\n",
    "plt.suptitle('US Stocks P/E by Sector for past 10 yrs', fontweight='bold', fontsize=11)\n",
    "plt.subplots_adjust(top=0.91, bottom=0.08, hspace=0.4)\n",
    "_ = plt.xticks(ticks=x, labels=list(map(lambda col: col[3:], cols)), fontsize=8, fontweight='bold')\n",
    "for label in ax.xaxis.get_ticklabels():\n",
    "    label.set_rotation(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to the top](#top)\n",
    "#### P/S by Sector for past 10 yrs for US Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.709964Z",
     "start_time": "2024-09-10T03:41:02.747315Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = list(filter(lambda col: col.startswith('PS_'), df.columns))\n",
    "\n",
    "fig, axs = plt.subplots(11, 1, figsize=(7, 6), sharex=True)\n",
    "sectors = df_val_mean_USA.index.values\n",
    "x = list(range(11))\n",
    "\n",
    "for sector, ax in zip(sectors, axs):\n",
    "    y = df_val_mean_USA[cols].loc[sector].values\n",
    "    p0 = ax.bar(x, y, width=0.5)\n",
    "    #ax.set_title(sector, loc='left', fontsize=9, fontweight='bold')\n",
    "    ax.spines['left'].set_color(None)\n",
    "    ax.spines['right'].set_color(None)\n",
    "    ax.spines['top'].set_color(None)\n",
    "    for pt in list(zip(x, y)):\n",
    "        if pt[1] > 0:\n",
    "            ax.text(pt[0], pt[1] + max(y)*0.05, '{:.0f}'.format(pt[1]), ha='center', fontsize=8)\n",
    "    ax.set_yticks([])\n",
    "    ax.axis([-5.5, 11, 0, max(y)+10])\n",
    "    ax.set_xlim(-5.5, 11)\n",
    "    ax.text(-5.5, max(y)+10, sector, fontweight='bold', fontsize=8)\n",
    "    ax0 = ax\n",
    "\n",
    "plt.suptitle('US Stocks P/S by Sector for past 10 yrs', fontweight='bold', fontsize=11)\n",
    "plt.subplots_adjust(top=0.91, bottom=0.08, hspace=0.4)\n",
    "_ = plt.xticks(ticks=x, labels=list(map(lambda col: col[3:], cols)), fontsize=8, fontweight='bold')\n",
    "for label in ax.xaxis.get_ticklabels():\n",
    "    label.set_rotation(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to the top](#top)\n",
    "### Stocks in the Cannabis Industry\n",
    "Using stocks listed on [marijuanaindex.com](http://marijuanaindex.com/stock-quotes/north-american-marijuana-index/) under North America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.710257Z",
     "start_time": "2024-09-10T03:41:02.749632Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('input/pot_stocks.json') as file:\n",
    "    pot_symbols = json.loads(file.read())\n",
    "\n",
    "pot_stocks = (pd.DataFrame(pot_symbols, columns=['ticker', 'country_c3'])\n",
    "               .merge(df_master, how='left', on=['ticker', 'country_c3']).drop('country', axis=1)\n",
    "               .rename(columns={'country_c3':'country', 'exchange_sym':'exch'}))\n",
    "\n",
    "pot_stocks = (pot_stocks.where(((pot_stocks['country'] == 'USA') |\n",
    "                                (pot_stocks['country'] == 'CAN')) &\n",
    "                               (pot_stocks['sector'] != '—'))\n",
    "              .dropna(axis=0, how='all').sort_values(by='company'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.710578Z",
     "start_time": "2024-09-10T03:41:02.752083Z"
    }
   },
   "outputs": [],
   "source": [
    "msg = 'Below are the {} stocks listed on marijuanaindex.com for North America.'\n",
    "print(msg.format(len(pot_stocks['company'].unique())))\n",
    "\n",
    "pot_stocks[['country', 'ticker', 'exch', 'company', 'sector', 'industry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"value\"></a>\n",
    "[return to the top](#top)\n",
    "\n",
    "# Applying various criteria to filter common stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of different rules that can be applied to the data to screen stocks (development of *italicized rules* is still in progress)\n",
    "\n",
    "- **[Rule 0](#rule99): CAGR > 7% for past 7 years**\n",
    "- **[Rule 1](#rule1): No earnings deficit (loss) for past 5 or 7 years**\n",
    "- **[Rule 2](#rule2): Uniterrupted and increasing Dividends for past 5 yrs**\n",
    "- **[Rule 3](#rule3): P/E Ratio of 25 or less for the past 7 yrs and less then 20 for TTM**\n",
    "- **[Rule 4](#rule4): Growth for the past year**\n",
    "- **[Rule 5](#rule5): Current Ratio > 1.2**\n",
    "- **[Rule 6](#rule6): Debt/Equity < 1.0**\n",
    "- **[Rule 7](#rule7): Return on Equity > 10%**\n",
    "- **[Rule X](#rulex): Stocks with insider buys in the past 3 months**\n",
    "\n",
    "[Merge DataFrames](#mergerules) to screen stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to the top](#top)\n",
    "<a id=\"rule99\"></a>\n",
    "## Rule 0. CAGR > 7% for past 5 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column labels in `df_keyratios`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.710811Z",
     "start_time": "2024-09-10T03:41:02.754537Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_keyratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue CAGR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.711025Z",
     "start_time": "2024-09-10T03:41:02.756792Z"
    }
   },
   "outputs": [],
   "source": [
    "iid = 'i0'\n",
    "field = 'Rev'\n",
    "label = 'CAGR_{}'.format(field)\n",
    "\n",
    "df_rule0_Rev = (df_keyratios.where(df_keyratios['Y9'] > pd.to_datetime('2018-04-01')).dropna(axis=0, how='all'))\n",
    "\n",
    "df_rule0_Rev[label] = 100 * ((df_rule0_Rev['{}_Y9'.format(iid)] / df_rule0_Rev['{}_Y4'.format(iid)]) ** (1/5) - 1)\n",
    "\n",
    "cols = ['ticker_id', 'exchange_id', label] #, '{}_Y4'.format(iid), '{}_Y9'.format(iid)]\n",
    "df_rule0_Rev = (df_rule0_Rev.where(df_rule0_Rev[label] >= 7).dropna(axis=0, how='all')\n",
    "                .sort_values(by=label, ascending=False))[cols]\n",
    "\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule0_Rev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Income CAGR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.711239Z",
     "start_time": "2024-09-10T03:41:02.759222Z"
    }
   },
   "outputs": [],
   "source": [
    "iid = 'i2'\n",
    "field = 'OpeInc'\n",
    "label = 'CAGR_{}'.format(field)\n",
    "\n",
    "df_rule0_OpeInc = (df_keyratios.where(df_keyratios['Y9'] > pd.to_datetime('2018-04-01')).dropna(axis=0, how='all'))\n",
    "\n",
    "df_rule0_OpeInc[label] = 100 * (\n",
    "    (df_rule0_OpeInc['{}_Y9'.format(iid)] / df_rule0_OpeInc['{}_Y4'.format(iid)]) ** (1/5) - 1)\n",
    "\n",
    "cols = ['ticker_id', 'exchange_id', label]\n",
    "df_rule0_OpeInc = (df_rule0_OpeInc.where(df_rule0_OpeInc[label] >= 7).dropna(axis=0, how='all')\n",
    "                .sort_values(by=label, ascending=False))[cols]\n",
    "\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule0_OpeInc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Cash Flow CAGR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.711482Z",
     "start_time": "2024-09-10T03:41:02.761506Z"
    }
   },
   "outputs": [],
   "source": [
    "iid = 'i9'\n",
    "field = 'OpeCF'\n",
    "label = 'CAGR_{}'.format(field)\n",
    "\n",
    "df_rule0_OpeCF = (df_keyratios.where(df_keyratios['Y9'] > pd.to_datetime('2018-04-01')).dropna(axis=0, how='all'))\n",
    "\n",
    "df_rule0_OpeCF[label] = 100 * (\n",
    "    (df_rule0_OpeCF['{}_Y9'.format(iid)] / df_rule0_OpeCF['{}_Y4'.format(iid)]) ** (1/5) - 1)\n",
    "\n",
    "cols = ['ticker_id', 'exchange_id', label]\n",
    "df_rule0_OpeCF = (df_rule0_OpeCF.where(df_rule0_OpeCF[label] >= 7).dropna(axis=0, how='all')\n",
    "                .sort_values(by=label, ascending=False))[cols]\n",
    "\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule0_OpeCF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free Cash Flow CAGR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.711797Z",
     "start_time": "2024-09-10T03:41:02.763936Z"
    }
   },
   "outputs": [],
   "source": [
    "iid = 'i11'\n",
    "field = 'FreeCF'\n",
    "label = 'CAGR_{}'.format(field)\n",
    "\n",
    "df_rule0_FreeCF = (df_keyratios.where(df_keyratios['Y9'] > pd.to_datetime('2018-04-01')).dropna(axis=0, how='all'))\n",
    "df_rule0_FreeCF[label] = 100 * (\n",
    "    (df_rule0_FreeCF['{}_Y9'.format(iid)] / df_rule0_FreeCF['{}_Y4'.format(iid)]) ** (1/5) - 1)\n",
    "\n",
    "cols = ['ticker_id', 'exchange_id', label]\n",
    "df_rule0_FreeCF = (df_rule0_FreeCF.where(df_rule0_FreeCF[label] >= 7).dropna(axis=0, how='all')\n",
    "                .sort_values(by=label, ascending=False))[cols]\n",
    "\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule0_FreeCF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"rule1\"></a>\n",
    "### Rule 1. No earnings deficit (loss) for past 5 or 7 years\n",
    "Criteria: *\"Find companies with positive earnings per share growth during the past five years with no earnings deficits. Earnings need to be higher in the most recent year than five years ago. Avoiding companies with earnings deficits during the past five years will help you stay clear of high-risk companies.\"* [(Source)](https://cabotwealth.com/daily/value-investing/benjamin-grahams-value-stock-criteria/)\n",
    "\n",
    "#### 5 Years: (PENDING CORRECTION OF CODE)\n",
    "*a. Identify Net Income column labels in* `df_annualIS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.712129Z",
     "start_time": "2024-09-10T03:41:02.766259Z"
    }
   },
   "outputs": [],
   "source": [
    "ilabel = 'Net income'\n",
    "df_labels = df_labels_aIS[df_labels_aIS['value'] == ilabel].sort_values(by='value')\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*b. Get column headers for 'Net income' values for the past 5 yrs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.712354Z",
     "start_time": "2024-09-10T03:41:02.768550Z"
    }
   },
   "outputs": [],
   "source": [
    "# i_ids = [(label[-3:] + '_') for label in df_labels.index]\n",
    "\n",
    "# def get_icols(col):\n",
    "#     for i_id in i_ids:\n",
    "#         if i_id in col:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "# main_cols = ['ticker_id', 'exchange_id', 'country', 'exchange_sym', 'ticker', 'company', 'sector', 'industry',\n",
    "#              'stock_type', 'style', 'Year_Y_6', 'Year_Y_5', 'Year_Y_4', 'Year_Y_3', 'Year_Y_2', 'Year_Y_1']\n",
    "# data_cols = sorted(list(filter(get_icols, df_annualIS.columns)), key=lambda r: (r[-1], r[5:8]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*c. Create 'Net Income' DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.712592Z",
     "start_time": "2024-09-10T03:41:02.770889Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_annualIS1 = df_master.merge(df_annualIS, on=['ticker_id', 'exchange_id'])\n",
    "\n",
    "# df_netinc5 = (df_annualIS1\n",
    "#               .where((df_annualIS1['security_type'] == 'Stock') &\n",
    "#                      (df_annualIS1['Year_Y_5'] > pd.to_datetime('2018-01')))\n",
    "#               .dropna(axis=0, how='all')\n",
    "#               .drop(['country'], axis=1)\n",
    "#               .rename(columns={'country_c3':'country'})\n",
    "#              )[main_cols + data_cols]\n",
    "\n",
    "# np_netinc = df_netinc5[data_cols].values\n",
    "# netinc_cols = [('NetIncome_Y' + data_cols[i * 3][-1], (i * 3, i * 3 + 1, i * 3 + 2))\n",
    "#                for i in range(int(len(data_cols)/3))]\n",
    "\n",
    "# vals = []\n",
    "# for row in np_netinc:\n",
    "#     row_vals = []\n",
    "#     for i in range(len(netinc_cols)):\n",
    "#         val = None\n",
    "#         for col in netinc_cols[i][1]:\n",
    "#             if not np.isnan(row[col]):\n",
    "#                 val = row[col]\n",
    "#                 break\n",
    "#         row_vals.append(val)\n",
    "#     vals.append(row_vals)\n",
    "\n",
    "# df_netinc_vals = pd.DataFrame(vals, columns=list(zip(*netinc_cols))[0])\n",
    "# df_netinc5 = df_netinc5[main_cols].join(df_netinc_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.712811Z",
     "start_time": "2024-09-10T03:41:02.773251Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_rule1_5 = df_netinc5.where((df_netinc5['NetIncome_Y6'] > 0) &\n",
    "#                             ((df_netinc5['NetIncome_Y5'] > 0) | (df_netinc5['NetIncome_Y5'].isna() & df_netinc5['NetIncome_Y4'].isna() & df_netinc5['NetIncome_Y3'].isna() & df_netinc5['NetIncome_Y2'].isna() & df_netinc5['NetIncome_Y1'].isna())) &\n",
    "#                             ((df_netinc5['NetIncome_Y4'] > 0) | (df_netinc5['NetIncome_Y4'].isna() & df_netinc5['NetIncome_Y3'].isna() & df_netinc5['NetIncome_Y2'].isna() & df_netinc5['NetIncome_Y1'].isna())) &\n",
    "#                             ((df_netinc5['NetIncome_Y3'] > 0) | (df_netinc5['NetIncome_Y3'].isna() & df_netinc5['NetIncome_Y2'].isna() & df_netinc5['NetIncome_Y1'].isna())) &\n",
    "#                             ((df_netinc5['NetIncome_Y2'] > 0) | (df_netinc5['NetIncome_Y2'].isna() & df_netinc5['NetIncome_Y1'].isna())) &\n",
    "#                             ((df_netinc5['NetIncome_Y1'] > 0) | (df_netinc5['NetIncome_Y1'].isna()))\n",
    "#                            ).dropna(axis=0, how='all')\n",
    "\n",
    "# df_rule1_5 = df_rule1_5[['ticker_id', 'exchange_id'] + df_rule1_5.columns.values.tolist()[-12:]]\n",
    "# df_rule1_5.columns = [re.sub('Year_Y_', 'r1_Y', col) for col in df_rule1_5.columns]\n",
    "\n",
    "# print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule1_5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.713019Z",
     "start_time": "2024-09-10T03:41:02.775497Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['ticker_id', 'exchange_id'] + \\\n",
    "        [col for col in df_keyratios.columns if col.startswith('i4_') or col.startswith('Y')]\n",
    "\n",
    "df_rule1_5 = (df_keyratios\n",
    "              .where((df_keyratios['Y9'] >= pd.to_datetime('2018-04-01')) &\n",
    "                     (df_keyratios['i4_Y10'] > 0) &\n",
    "                     ((df_keyratios['i4_Y9'] > 0) | (df_keyratios['i4_Y9'].isna() & df_keyratios['i4_Y8'].isna() & df_keyratios['i4_Y7'].isna() & df_keyratios['i4_Y6'].isna() & df_keyratios['i4_Y5'].isna())) &\n",
    "                     ((df_keyratios['i4_Y8'] > 0) | (df_keyratios['i4_Y8'].isna() & df_keyratios['i4_Y7'].isna() & df_keyratios['i4_Y6'].isna() & df_keyratios['i4_Y5'].isna())) &\n",
    "                     ((df_keyratios['i4_Y7'] > 0) | (df_keyratios['i4_Y7'].isna() & df_keyratios['i4_Y6'].isna() & df_keyratios['i4_Y5'].isna())) &\n",
    "                     ((df_keyratios['i4_Y6'] > 0) | (df_keyratios['i4_Y6'].isna() & df_keyratios['i4_Y5'].isna())) &\n",
    "                     ((df_keyratios['i4_Y5'] > 0) | (df_keyratios['i4_Y5'].isna())))\n",
    "              .dropna(axis=0, how='all'))[cols]\n",
    "\n",
    "df_rule1_5.columns = [re.sub('i4_', 'NetIncome_', col) for col in df_rule1_5.columns]\n",
    "df_rule1_5.columns = [re.sub('^Y', 'r1_Y', col) for col in df_rule1_5.columns]\n",
    "\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule1_5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 Years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.713244Z",
     "start_time": "2024-09-10T03:41:02.777873Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['ticker_id', 'exchange_id'] + \\\n",
    "        [col for col in df_keyratios.columns if col.startswith('i4_') or col.startswith('Y')]\n",
    "\n",
    "df_rule1_7 = (df_keyratios\n",
    "              .where((df_keyratios['Y9'] >= pd.to_datetime('2018-04-01')) &\n",
    "                     (df_keyratios['i4_Y10'] > 0) &\n",
    "                     ((df_keyratios['i4_Y9'] > 0) | (df_keyratios['i4_Y9'].isna() & df_keyratios['i4_Y8'].isna() & df_keyratios['i4_Y7'].isna() & df_keyratios['i4_Y6'].isna() & df_keyratios['i4_Y5'].isna() & df_keyratios['i4_Y4'].isna() & df_keyratios['i4_Y3'].isna())) &\n",
    "                     ((df_keyratios['i4_Y8'] > 0) | (df_keyratios['i4_Y8'].isna() & df_keyratios['i4_Y7'].isna() & df_keyratios['i4_Y6'].isna() & df_keyratios['i4_Y5'].isna() & df_keyratios['i4_Y4'].isna() & df_keyratios['i4_Y3'].isna())) &\n",
    "                     ((df_keyratios['i4_Y7'] > 0) | (df_keyratios['i4_Y7'].isna() & df_keyratios['i4_Y6'].isna() & df_keyratios['i4_Y5'].isna() & df_keyratios['i4_Y4'].isna() & df_keyratios['i4_Y3'].isna())) &\n",
    "                     ((df_keyratios['i4_Y6'] > 0) | (df_keyratios['i4_Y6'].isna() & df_keyratios['i4_Y5'].isna() & df_keyratios['i4_Y4'].isna() & df_keyratios['i4_Y3'].isna())) &\n",
    "                     ((df_keyratios['i4_Y5'] > 0) | (df_keyratios['i4_Y5'].isna() & df_keyratios['i4_Y4'].isna() & df_keyratios['i4_Y3'].isna())) &\n",
    "                     ((df_keyratios['i4_Y4'] > 0) | (df_keyratios['i4_Y4'].isna() & df_keyratios['i4_Y3'].isna())) &\n",
    "                     ((df_keyratios['i4_Y3'] > 0) | (df_keyratios['i4_Y3'].isna())))\n",
    "              .dropna(axis=0, how='all'))[cols]\n",
    "\n",
    "df_rule1_7.columns = [re.sub('i4_', 'NetIncome_', col) for col in df_rule1_7.columns]\n",
    "df_rule1_7.columns = [re.sub('^Y', 'r1_Y', col) for col in df_rule1_7.columns]\n",
    "\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule1_7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"rule2\"></a>\n",
    "### Rule 2. Uniterrupted and increasing *Dividends* for past 7 yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.713531Z",
     "start_time": "2024-09-10T03:41:02.780163Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_keyratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.713749Z",
     "start_time": "2024-09-10T03:41:02.782445Z"
    }
   },
   "outputs": [],
   "source": [
    "icol = df_labels_keyratios[df_labels_keyratios.str.contains('Dividends')].index[0]\n",
    "icol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.713961Z",
     "start_time": "2024-09-10T03:41:02.784848Z"
    }
   },
   "outputs": [],
   "source": [
    "main_cols = ['ticker_id', 'exchange_id',\n",
    "             #'country_c3', 'exchange_sym', 'ticker', 'company',\n",
    "             #'sector', 'industry', 'stock_type', 'style',\n",
    "             'Y10', 'Y9', 'Y8', 'Y7', 'Y6', 'Y5']\n",
    "icols = sorted([col for col in df_keyratios.columns if icol + '_' in col],\n",
    "               key=lambda col: int(col[4:]), reverse=True)[:8]\n",
    "icols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.714169Z",
     "start_time": "2024-09-10T03:41:02.787152Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rule2 = (df_keyratios\n",
    "            .where((df_keyratios['Y9'] > pd.to_datetime('2018-04-01')) &\n",
    "                   (df_keyratios['i6_Y10'] >= df_keyratios['i6_Y9']) &\n",
    "                   ((df_keyratios['i6_Y9'] >= df_keyratios['i6_Y8']) | (df_keyratios['i6_Y2'].isna() & df_keyratios['i6_Y3'].isna() & df_keyratios['i6_Y4'].isna() & df_keyratios['i6_Y5'].isna() & df_keyratios['i6_Y6'].isna() & df_keyratios['i6_Y7'].isna() & df_keyratios['i6_Y8'].isna())) &\n",
    "                   ((df_keyratios['i6_Y8'] >= df_keyratios['i6_Y7']) | (df_keyratios['i6_Y2'].isna() & df_keyratios['i6_Y3'].isna() & df_keyratios['i6_Y4'].isna() & df_keyratios['i6_Y5'].isna() & df_keyratios['i6_Y6'].isna() & df_keyratios['i6_Y7'].isna())) &\n",
    "                   ((df_keyratios['i6_Y7'] >= df_keyratios['i6_Y6']) | (df_keyratios['i6_Y2'].isna() & df_keyratios['i6_Y3'].isna() & df_keyratios['i6_Y4'].isna() & df_keyratios['i6_Y5'].isna() & df_keyratios['i6_Y6'].isna())) &\n",
    "                   ((df_keyratios['i6_Y6'] >= df_keyratios['i6_Y5']) | (df_keyratios['i6_Y2'].isna() & df_keyratios['i6_Y3'].isna() & df_keyratios['i6_Y4'].isna() & df_keyratios['i6_Y5'].isna())) &\n",
    "                   ((df_keyratios['i6_Y5'] >= df_keyratios['i6_Y4']) | (df_keyratios['i6_Y2'].isna() & df_keyratios['i6_Y3'].isna() & df_keyratios['i6_Y4'].isna())) &\n",
    "                   ((df_keyratios['i6_Y4'] >= df_keyratios['i6_Y3']) | (df_keyratios['i6_Y2'].isna() & df_keyratios['i6_Y3'].isna())) &\n",
    "                   ((df_keyratios['i6_Y3'] >= df_keyratios['i6_Y2']) | (df_keyratios['i6_Y2'].isna())))\n",
    "            .dropna(axis=0, how='all').sort_values(by='Y9', ascending=False))[main_cols + icols]\n",
    "\n",
    "df_rule2.columns = main_cols + [col.replace('i6', 'Dividend') for col in icols]\n",
    "df_rule2.columns = [re.sub('^Y', 'r2_Y', col) for col in df_rule2.columns]\n",
    "\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"rule3\"></a>\n",
    "### Rule 3. P/E Ratio of 25 or less for the past 7 yrs and less then 20 for TTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.714412Z",
     "start_time": "2024-09-10T03:41:02.789423Z"
    }
   },
   "outputs": [],
   "source": [
    "pe_cols = [col for col in df_vals.columns if 'PE_' in col]\n",
    "pe_cols = ['ticker_id', 'exchange_id'] + [pe_cols[len(pe_cols)-i-1] for i in range(len(pe_cols))][:8]\n",
    "pe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.714666Z",
     "start_time": "2024-09-10T03:41:02.791763Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rule3 = (df_vals[pe_cols]\n",
    "            .where((df_vals['PE_TTM'] <= 10) &\n",
    "                   (df_vals['PE_2018'] <= 25) &\n",
    "                   ((df_vals['PE_2017'] <= 25) | (df_vals['PE_2012'].isna() & df_vals['PE_2013'].isna() & df_vals['PE_2014'].isna() & df_vals['PE_2015'].isna() & df_vals['PE_2016'].isna() & df_vals['PE_2017'].isna())) &\n",
    "                   ((df_vals['PE_2016'] <= 25) | (df_vals['PE_2012'].isna() & df_vals['PE_2013'].isna() & df_vals['PE_2014'].isna() & df_vals['PE_2015'].isna() & df_vals['PE_2016'].isna())) &\n",
    "                   ((df_vals['PE_2015'] <= 25) | (df_vals['PE_2012'].isna() & df_vals['PE_2013'].isna() & df_vals['PE_2014'].isna() & df_vals['PE_2015'].isna())) &\n",
    "                   ((df_vals['PE_2014'] <= 25) | (df_vals['PE_2012'].isna() & df_vals['PE_2013'].isna() & df_vals['PE_2014'].isna())) &\n",
    "                   ((df_vals['PE_2013'] <= 25) | (df_vals['PE_2012'].isna() & df_vals['PE_2013'].isna())) &\n",
    "                   ((df_vals['PE_2012'] <= 25) | (df_vals['PE_2012'].isna())))\n",
    "            .dropna(axis=0, how='all').sort_values(by='PE_TTM'))\n",
    "\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"rule4\"></a>\n",
    "## Rule 4. Growth for the past year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.714897Z",
     "start_time": "2024-09-10T03:41:02.794202Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.715117Z",
     "start_time": "2024-09-10T03:41:02.796428Z"
    }
   },
   "outputs": [],
   "source": [
    "iid = 'i28'; label = '{}_gr_Y9'.format(iid); col = 'Rev';\n",
    "cols = ['ticker_id', 'exchange_id', 'gr_Y9', label]\n",
    "df_rule4_Rev = (df_growth[cols]\n",
    "                .where((df_growth[label] > 0) & (df_growth['gr_Y9'] > pd.to_datetime('2018-04-01')))\n",
    "                .dropna(axis=0, how='all').sort_values(by='gr_Y9')\n",
    "                .rename(columns={label:'{}_Growth_Y9'.format(col)}))\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule4_Rev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.715406Z",
     "start_time": "2024-09-10T03:41:02.798668Z"
    }
   },
   "outputs": [],
   "source": [
    "iid = 'i32'; label = '{}_gr_Y9'.format(iid); col = 'OpeInc';\n",
    "cols = ['ticker_id', 'exchange_id', 'gr_Y9', label]\n",
    "df_rule4_OpeInc = (df_growth[cols]\n",
    "                .where((df_growth[label] > 0) & (df_growth['gr_Y9'] > pd.to_datetime('2018-04-01')))\n",
    "                .dropna(axis=0, how='all').sort_values(by='gr_Y9')\n",
    "                .rename(columns={label:'{}_Growth_Y9'.format(col)}))\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule4_OpeInc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.715665Z",
     "start_time": "2024-09-10T03:41:02.800981Z"
    }
   },
   "outputs": [],
   "source": [
    "iid = 'i81'; label = '{}_gr_Y9'.format(iid); col = 'NetInc';\n",
    "cols = ['ticker_id', 'exchange_id', 'gr_Y9', label]\n",
    "df_rule4_NetInc = (df_growth[cols]\n",
    "                .where((df_growth[label] > 0) & (df_growth['gr_Y9'] > pd.to_datetime('2018-04-01')))\n",
    "                .dropna(axis=0, how='all').sort_values(by='gr_Y9')\n",
    "                .rename(columns={label:'{}_Growth_Y9'.format(col)}))\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule4_NetInc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"rule5\"></a>\n",
    "### Rule 5. Current Ratio > 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.715892Z",
     "start_time": "2024-09-10T03:41:02.803327Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_finhealth[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.716108Z",
     "start_time": "2024-09-10T03:41:02.805590Z"
    }
   },
   "outputs": [],
   "source": [
    "col = 'i65_lfh_Y10'\n",
    "df_rule5 = (df_finhealth[['ticker_id', 'exchange_id', col]]\n",
    "            .where((df_finhealth[col] > 1.2) | (df_finhealth[col].isna()))\n",
    "            .dropna(axis=0, how='all')\n",
    "            .rename(columns={col:'current_ratio'}))\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"rule6\"></a>\n",
    "### Rule 6. Debt/Equity < 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.716408Z",
     "start_time": "2024-09-10T03:41:02.807790Z"
    }
   },
   "outputs": [],
   "source": [
    "col = 'i68_lfh_Y10'\n",
    "df_rule6 = (df_finhealth[['ticker_id', 'exchange_id', col]]\n",
    "            .where((df_finhealth[col] < 1.5) | (df_finhealth[col].isna()))\n",
    "            .dropna(axis=0, how='all')\n",
    "            .rename(columns={col:'debt2equity'}))\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"rule7\"></a>\n",
    "### Rule 7. Return on Equity > 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.716689Z",
     "start_time": "2024-09-10T03:41:02.810085Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_profitab[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.716906Z",
     "start_time": "2024-09-10T03:41:02.812378Z"
    }
   },
   "outputs": [],
   "source": [
    "col = 'i26_pr_pro_Y10'\n",
    "df_rule7 = (df_profitab[['ticker_id', 'exchange_id', col]]\n",
    "            .where((df_profitab[col] > 10) | (df_profitab[col].isna()))\n",
    "            .dropna(axis=0, how='all')\n",
    "            .rename(columns={col:'return_on_equity'}))\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"rule7\"></a>\n",
    "### Rule 8. P/B < 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.717125Z",
     "start_time": "2024-09-10T03:41:02.814709Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rule8 = df_vals.where(df_vals['PB_TTM'] <= 1).dropna(axis=0, how='all')\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_rule8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"rulex\"></a>\n",
    "### Rule X. Stocks with insider buys in the past 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.717341Z",
     "start_time": "2024-09-10T03:41:02.817058Z"
    }
   },
   "outputs": [],
   "source": [
    "datefilter = pd.to_datetime(DT.date.today()-DT.timedelta(days=90))\n",
    "\n",
    "df_insiderbuys0 = (df_insidertrades\n",
    "                  .where((df_insidertrades['type'] == 'Buy') & (df_insidertrades['date'] >= datefilter))\n",
    "                  .dropna(axis=0, how='all').groupby(['ticker_id', 'exchange_id']).sum())\n",
    "\n",
    "\n",
    "df_insiderbuys = (df_master.set_index(['ticker_id', 'exchange_id'])\n",
    "                  .join(df_insiderbuys0, how='inner').reset_index()\n",
    "                  .groupby(['company', 'sector', 'industry']).mean().round(1)\n",
    "                  .sort_values(by='value', ascending=False)\n",
    "                 )[['openprice', 'yield', 'quantity', 'value']]\n",
    "\n",
    "print('Total of {:,.0f} records meet this criterium.'.format(len(df_insiderbuys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.717591Z",
     "start_time": "2024-09-10T03:41:02.819297Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('doc/df_insiderbuys.csv', 'w') as file:\n",
    "    file.write(df_insiderbuys.to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[return to top of this section](#value),\n",
    "[return to the top](#top)\n",
    "<a id=\"mergerules\"></a>\n",
    "### Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.717844Z",
     "start_time": "2024-09-10T03:41:02.821571Z"
    }
   },
   "outputs": [],
   "source": [
    "df_master.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.718065Z",
     "start_time": "2024-09-10T03:41:02.823940Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rules = (df_master[df_master['security_type'] == 'Stock']\n",
    "            #.merge(df_rule0_Rev, on=['ticker_id', 'exchange_id'])    # CAGR > 7% for past 5 yrs - Revenue\n",
    "            #.merge(df_rule0_OpeInc, on=['ticker_id', 'exchange_id']) # CAGR > 7% for past 5 yrs - Ope. Income\n",
    "            #.merge(df_rule0_OpeCF, on=['ticker_id', 'exchange_id'])  # CAGR > 7% for past 5 yrs - Ope. Cash Flow\n",
    "            #.merge(df_rule0_FreeCF, on=['ticker_id', 'exchange_id']) # CAGR > 7% for past 5 yrs - Free Cash Flow\n",
    "            .merge(df_rule1_5, on=['ticker_id', 'exchange_id'])      # No earnings deficit for past 5 yrs\n",
    "            .merge(df_rule2, on=['ticker_id', 'exchange_id'])        # Uniterrupted Dividends for past 7 yrs\n",
    "            .merge(df_rule3, on=['ticker_id', 'exchange_id'])        # P/E Ratio of 10 or less for past 7 yrs\n",
    "            .merge(df_rule4_Rev, on=['ticker_id', 'exchange_id'])    # Growth for the past year - Revenue\n",
    "            .merge(df_rule4_OpeInc, on=['ticker_id', 'exchange_id']) # Growth for the past year - Ope. Income\n",
    "            .merge(df_rule4_NetInc, on=['ticker_id', 'exchange_id']) # Growth for the past year - Net Income\n",
    "            .merge(df_rule5, on=['ticker_id', 'exchange_id'])        # Current Ratio > 1.2\n",
    "            .merge(df_rule6, on=['ticker_id', 'exchange_id'])        # Debt/Equity < 1.0\n",
    "            .merge(df_rule7, on=['ticker_id', 'exchange_id'])        # Return on Equity > 10%\n",
    "            .merge(df_rule8, on=['ticker_id', 'exchange_id'])        # P/B < 1.0\n",
    "            #.merge(df_insiderbuys0, on=['ticker_id', 'exchange_id'])  # Insider buys in the past 3 months\n",
    "            #.merge(df_vals[['ticker_id', 'exchange_id', 'PB_TTM', 'PS_TTM', 'PC_TTM']],\n",
    "            #       on=['ticker_id', 'exchange_id'])\n",
    "\n",
    "            #.groupby(['company', 'exchange_sym', 'ticker', 'sector', 'industry']).mean().round(1)\n",
    "           )[['company', 'exchange_sym', 'ticker', 'sector', 'industry',\n",
    "              'lastprice', 'yield', '_52wk_hi', '_52wk_lo',\n",
    "              'PE_TTM_x', 'PB_TTM', 'PS_TTM', 'PC_TTM', 'current_ratio', 'debt2equity', 'return_on_equity',\n",
    "              #'CAGR_Rev', 'CAGR_OpeInc', 'CAGR_OpeCF', 'CAGR_FreeCF',\n",
    "              'Rev_Growth_Y9', 'OpeInc_Growth_Y9', 'NetInc_Growth_Y9'#, 'value'\n",
    "              ]]\n",
    "\n",
    "total_companies = df_master[df_master['security_type'] == 'Stock']#.groupby('company').count()\n",
    "msg = 'A total of {:,.0f} stocks meet these criteria out of {:,.0f} (as of {})'\n",
    "print(msg.format(len(df_rules), len(total_companies), DT.date.today()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.718280Z",
     "start_time": "2024-09-10T03:41:02.826178Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.718486Z",
     "start_time": "2024-09-10T03:41:02.828485Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('doc/df_rules.csv', 'w') as file:\n",
    "    file.write(df_rules.to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"additional\"></a>\n",
    "[return to the top](#top)\n",
    "\n",
    "## Additional sample / test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.718689Z",
     "start_time": "2024-09-10T03:41:02.830739Z"
    }
   },
   "outputs": [],
   "source": "import requests"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.718930Z",
     "start_time": "2024-09-10T03:41:02.833018Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'http://performance.morningstar.com/perform/Performance/stock/exportStockPrice.action?t={}:{}&pd=1yr&freq=d&pg=0&culture=en-US'\n",
    "req = requests.get(url.format('xnas', 'aaoi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:20:29.719145Z",
     "start_time": "2024-09-10T03:41:02.835421Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
